{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af48f934-c60b-4508-bdbc-8c61f3b4f1ff",
   "metadata": {},
   "source": [
    "# CSGO Match Prediction with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dc9b162-2c96-47e0-ae0d-41a235ec32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c14e84d-5dad-4305-8408-5fee74915ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas to try\n",
    "# ============\n",
    "# - higher learning rate, higher c, with one hot encoding\n",
    "# - polyfit with no one-hot\n",
    "# - polyfit with one hot\n",
    "# - psuedo one-hot encoding vs summing winner data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2d53b-6c11-4128-aa68-9ec2935b4996",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c423bc-4fff-4cc4-abca-f9f806f51d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142ab1f0-e934-49c7-93dd-72ca0162ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "429436c6-c0e0-456a-9745-83255449dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = []\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a2126d-7314-48d1-96f1-4ad25d04bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3ee573-7373-440e-b7d8-c8b0f28e96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7d926a5-65b4-4913-a3c1-2b0bc66a6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f612806f-c357-493e-9a6e-b2cc32185d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/34/wwdjpw3x60scvghx_lqvyv440000gp/T/ipykernel_122/2170638273.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "/var/folders/34/wwdjpw3x60scvghx_lqvyv440000gp/T/ipykernel_122/2170638273.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>_map</th>\n",
       "      <th>1_t1</th>\n",
       "      <th>2_t1</th>\n",
       "      <th>3_t1</th>\n",
       "      <th>4_t1</th>\n",
       "      <th>5_t1</th>\n",
       "      <th>6_t1</th>\n",
       "      <th>7_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>7_winner</th>\n",
       "      <th>8_winner</th>\n",
       "      <th>9_winner</th>\n",
       "      <th>10_winner</th>\n",
       "      <th>11_winner</th>\n",
       "      <th>12_winner</th>\n",
       "      <th>13_winner</th>\n",
       "      <th>14_winner</th>\n",
       "      <th>15_winner</th>\n",
       "      <th>t1_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>28500.0</td>\n",
       "      <td>31900.0</td>\n",
       "      <td>31700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>263</td>\n",
       "      <td>1480</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>23150.0</td>\n",
       "      <td>21850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1480</td>\n",
       "      <td>2784</td>\n",
       "      <td>1</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>18050.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>25850.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>27250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480</td>\n",
       "      <td>2784</td>\n",
       "      <td>0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24500.0</td>\n",
       "      <td>27550.0</td>\n",
       "      <td>29350.0</td>\n",
       "      <td>31950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43229</th>\n",
       "      <td>2048</td>\n",
       "      <td>726</td>\n",
       "      <td>9</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>26750.0</td>\n",
       "      <td>27450.0</td>\n",
       "      <td>26950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43230</th>\n",
       "      <td>2784</td>\n",
       "      <td>1117</td>\n",
       "      <td>4</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>17400.0</td>\n",
       "      <td>22050.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>25650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43231</th>\n",
       "      <td>2195</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>29150.0</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43232</th>\n",
       "      <td>2350</td>\n",
       "      <td>1076</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>22950.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>26850.0</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43233</th>\n",
       "      <td>1040</td>\n",
       "      <td>1721</td>\n",
       "      <td>8</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43234 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_1  team_2  _map    1_t1     2_t1     3_t1     4_t1     5_t1  \\\n",
       "0         263    1480     0  4350.0   1100.0  22100.0   9350.0  25750.0   \n",
       "1         263    1480     1  3900.0   7400.0  23250.0  28500.0  31900.0   \n",
       "2         263    1480     2  4150.0  14300.0   2000.0  24800.0   9000.0   \n",
       "3        1480    2784     1  4150.0  18050.0  21000.0  25850.0  25000.0   \n",
       "4        1480    2784     0  4200.0  10000.0  22000.0  24500.0  27550.0   \n",
       "...       ...     ...   ...     ...      ...      ...      ...      ...   \n",
       "43229    2048     726     9  4250.0   7400.0  17200.0  18500.0  26750.0   \n",
       "43230    2784    1117     4  4250.0   1600.0  24250.0  17400.0  22050.0   \n",
       "43231    2195      96     2  4350.0   7650.0  20000.0  21500.0  29150.0   \n",
       "43232    2350    1076     2  4150.0  11800.0   1200.0  22950.0  25750.0   \n",
       "43233    1040    1721     8  4100.0  17700.0  18950.0  13200.0  24000.0   \n",
       "\n",
       "          6_t1     7_t1  ...  7_winner  8_winner  9_winner  10_winner  \\\n",
       "0      10400.0  24600.0  ...       2.0       2.0       1.0        2.0   \n",
       "1      31700.0  18950.0  ...       2.0       1.0       1.0        2.0   \n",
       "2      23150.0  21850.0  ...       1.0       2.0       2.0        2.0   \n",
       "3      25000.0  27250.0  ...       1.0       1.0       1.0        1.0   \n",
       "4      29350.0  31950.0  ...       2.0       1.0       1.0        1.0   \n",
       "...        ...      ...  ...       ...       ...       ...        ...   \n",
       "43229  27450.0  26950.0  ...       2.0       1.0       2.0        2.0   \n",
       "43230   6600.0  25650.0  ...       1.0       1.0       1.0        1.0   \n",
       "43231  26900.0   8750.0  ...       2.0       2.0       2.0        1.0   \n",
       "43232  26850.0  27850.0  ...       1.0       1.0       2.0        1.0   \n",
       "43233  20550.0  14500.0  ...       1.0       1.0       1.0        2.0   \n",
       "\n",
       "       11_winner  12_winner  13_winner  14_winner  15_winner  t1_t  \n",
       "0            2.0        2.0        2.0        2.0        2.0     1  \n",
       "1            2.0        2.0        2.0        2.0        2.0     0  \n",
       "2            2.0        2.0        2.0        2.0        2.0     1  \n",
       "3            1.0        1.0        1.0        1.0        1.0     1  \n",
       "4            1.0        1.0        1.0        1.0        1.0     0  \n",
       "...          ...        ...        ...        ...        ...   ...  \n",
       "43229        2.0        2.0        2.0        2.0        2.0     1  \n",
       "43230        1.0        1.0        2.0        2.0        2.0     1  \n",
       "43231        1.0        2.0        2.0        1.0        1.0     0  \n",
       "43232        1.0        1.0        1.0        1.0        1.0     1  \n",
       "43233        1.0        1.0        1.0        1.0        1.0     1  \n",
       "\n",
       "[43234 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624b06c7-8987-447e-bbbb-60170adfd8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "43229    2.0\n",
       "43230    1.0\n",
       "43231    1.0\n",
       "43232    1.0\n",
       "43233    1.0\n",
       "Name: match_winner, Length: 43234, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a06041",
   "metadata": {},
   "source": [
    "Split and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da8af287-2fa6-46d0-add4-7cf1effdfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472a55f-7c43-4dec-bc45-21e2664b21cd",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa21998",
   "metadata": {},
   "source": [
    "Now multiple neural networks will be fit to the data. A variety of network architecture and feature transformations are tried\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09a609-5f27-4a78-beec-795d88d6edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(8, 8, 8), solver='adam')\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4137c5-0aa2-43d9-a1dc-2258f62e1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Set Results\")\n",
    "print(confusion_matrix(y_train,predict_train))\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31d39c-7fce-4431-8c5b-f3d40bd8fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validaton Set Results\")\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050515bd",
   "metadata": {},
   "source": [
    "Polynomial transformations from degree 2 to 5 are tried. The mean squared error is calculated for each and plotted to determine which degree transformation performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859dcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "degrees = np.arange(2, 4)\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    print(\"Transforming features to polynomial degree %d\" % deg)\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    print(\"Fitting neural net\")\n",
    "    poly_mlp = MLPClassifier(hidden_layer_sizes=(8, 8, 8), solver='adam', max_iter=1000)    \n",
    "    poly_mlp.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    print(\"Fit Deg: \", deg)\n",
    "    poly_predict_test = poly_mlp.predict(x_poly_train)\n",
    "    poly_predict = poly_mlp.predict(x_poly_test)\n",
    "    print(\"Predict Deg: \", deg)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    print(\"Training Set Results\")\n",
    "    print(confusion_matrix(y_train, poly_predict_test))\n",
    "    print(classification_report(y_train, poly_predict_test))\n",
    "    \n",
    "    print(\"Validaton Set Results\")\n",
    "    print(confusion_matrix(y_test,poly_predict))\n",
    "    print(classification_report(y_test,poly_predict))\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "    \n",
    "    del poly_features\n",
    "    del x_poly_train\n",
    "    del poly_mlp\n",
    "    del x_poly_test\n",
    "    del poly_predict\n",
    "    gc.collect()\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c649ad",
   "metadata": {},
   "source": [
    "Now different values for the learning rate will be tried using the best polynomial transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fda8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "degree = 2\n",
    "rmses = []\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"Training neural net with learning rate %f\" % learning_rate)\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    print(\"Fitting neural net\")\n",
    "    poly_mlp = MLPClassifier(hidden_layer_sizes=(8, 8, 8), activation='relu', solver='adam', max_iter=1000, learning_rate_init=learning_rate)    \n",
    "    poly_mlp.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    poly_predict_test = poly_mlp.predict(x_poly_train)\n",
    "    poly_predict = poly_mlp.predict(x_poly_test)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    print(\"Training Set Results\")\n",
    "    print(confusion_matrix(y_train, poly_predict_test))\n",
    "    print(classification_report(y_train, poly_predict_test))\n",
    "    \n",
    "    print(\"Validaton Set Results\")\n",
    "    print(confusion_matrix(y_test,poly_predict))\n",
    "    print(classification_report(y_test,poly_predict))\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "    \n",
    "    del poly_features\n",
    "    del x_poly_train\n",
    "    del poly_mlp\n",
    "    del x_poly_test\n",
    "    del poly_predict\n",
    "    gc.collect()\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(learning_rate, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Learning Rate')\n",
    "ax.set_ylabel('RMSE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f83ea",
   "metadata": {},
   "source": [
    "And different values for network layers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e34dd84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural net with hidden layers  2\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[15687  2025]\n",
      " [ 5038  9675]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.89      0.82     17712\n",
      "         2.0       0.83      0.66      0.73     14713\n",
      "\n",
      "    accuracy                           0.78     32425\n",
      "   macro avg       0.79      0.77      0.77     32425\n",
      "weighted avg       0.79      0.78      0.78     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[4995  797]\n",
      " [1876 3141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.73      0.86      0.79      5792\n",
      "         2.0       0.80      0.63      0.70      5017\n",
      "\n",
      "    accuracy                           0.75     10809\n",
      "   macro avg       0.76      0.74      0.75     10809\n",
      "weighted avg       0.76      0.75      0.75     10809\n",
      "\n",
      "Training neural net with hidden layers  8\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[17327   385]\n",
      " [ 9847  4866]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.98      0.77     17712\n",
      "         2.0       0.93      0.33      0.49     14713\n",
      "\n",
      "    accuracy                           0.68     32425\n",
      "   macro avg       0.78      0.65      0.63     32425\n",
      "weighted avg       0.77      0.68      0.64     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[5613  179]\n",
      " [3361 1656]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.63      0.97      0.76      5792\n",
      "         2.0       0.90      0.33      0.48      5017\n",
      "\n",
      "    accuracy                           0.67     10809\n",
      "   macro avg       0.76      0.65      0.62     10809\n",
      "weighted avg       0.75      0.67      0.63     10809\n",
      "\n",
      "Training neural net with hidden layers  45\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[17673    39]\n",
      " [14102   611]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      1.00      0.71     17712\n",
      "         2.0       0.94      0.04      0.08     14713\n",
      "\n",
      "    accuracy                           0.56     32425\n",
      "   macro avg       0.75      0.52      0.40     32425\n",
      "weighted avg       0.73      0.56      0.43     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[5763   29]\n",
      " [4809  208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.99      0.70      5792\n",
      "         2.0       0.88      0.04      0.08      5017\n",
      "\n",
      "    accuracy                           0.55     10809\n",
      "   macro avg       0.71      0.52      0.39     10809\n",
      "weighted avg       0.70      0.55      0.41     10809\n",
      "\n",
      "Training neural net with hidden layers  (8, 8)\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[15710  2002]\n",
      " [ 6537  8176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.89      0.79     17712\n",
      "         2.0       0.80      0.56      0.66     14713\n",
      "\n",
      "    accuracy                           0.74     32425\n",
      "   macro avg       0.75      0.72      0.72     32425\n",
      "weighted avg       0.75      0.74      0.73     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[5110  682]\n",
      " [2265 2752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.69      0.88      0.78      5792\n",
      "         2.0       0.80      0.55      0.65      5017\n",
      "\n",
      "    accuracy                           0.73     10809\n",
      "   macro avg       0.75      0.72      0.71     10809\n",
      "weighted avg       0.74      0.73      0.72     10809\n",
      "\n",
      "Training neural net with hidden layers  (45, 8)\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[11150  6562]\n",
      " [ 1716 12997]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.63      0.73     17712\n",
      "         2.0       0.66      0.88      0.76     14713\n",
      "\n",
      "    accuracy                           0.74     32425\n",
      "   macro avg       0.77      0.76      0.74     32425\n",
      "weighted avg       0.77      0.74      0.74     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[3486 2306]\n",
      " [ 717 4300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.83      0.60      0.70      5792\n",
      "         2.0       0.65      0.86      0.74      5017\n",
      "\n",
      "    accuracy                           0.72     10809\n",
      "   macro avg       0.74      0.73      0.72     10809\n",
      "weighted avg       0.75      0.72      0.72     10809\n",
      "\n",
      "Training neural net with hidden layers  (45, 45)\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[ 5840 11872]\n",
      " [  447 14266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.33      0.49     17712\n",
      "         2.0       0.55      0.97      0.70     14713\n",
      "\n",
      "    accuracy                           0.62     32425\n",
      "   macro avg       0.74      0.65      0.59     32425\n",
      "weighted avg       0.76      0.62      0.58     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[1826 3966]\n",
      " [ 144 4873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.32      0.47      5792\n",
      "         2.0       0.55      0.97      0.70      5017\n",
      "\n",
      "    accuracy                           0.62     10809\n",
      "   macro avg       0.74      0.64      0.59     10809\n",
      "weighted avg       0.75      0.62      0.58     10809\n",
      "\n",
      "Training neural net with hidden layers  (8, 8, 8)\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[17712     0]\n",
      " [14713     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      1.00      0.71     17712\n",
      "         2.0       0.00      0.00      0.00     14713\n",
      "\n",
      "    accuracy                           0.55     32425\n",
      "   macro avg       0.27      0.50      0.35     32425\n",
      "weighted avg       0.30      0.55      0.39     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[5792    0]\n",
      " [5017    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      1.00      0.70      5792\n",
      "         2.0       0.00      0.00      0.00      5017\n",
      "\n",
      "    accuracy                           0.54     10809\n",
      "   macro avg       0.27      0.50      0.35     10809\n",
      "weighted avg       0.29      0.54      0.37     10809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taaseenali/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural net with hidden layers  (45, 8, 8)\n",
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[17712     0]\n",
      " [14713     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      1.00      0.71     17712\n",
      "         2.0       0.00      0.00      0.00     14713\n",
      "\n",
      "    accuracy                           0.55     32425\n",
      "   macro avg       0.27      0.50      0.35     32425\n",
      "weighted avg       0.30      0.55      0.39     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[5792    0]\n",
      " [5017    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      1.00      0.70      5792\n",
      "         2.0       0.00      0.00      0.00      5017\n",
      "\n",
      "    accuracy                           0.54     10809\n",
      "   macro avg       0.27      0.50      0.35     10809\n",
      "weighted avg       0.29      0.54      0.37     10809\n",
      "\n",
      "Training neural net with hidden layers  (45, 45, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taaseenali/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting neural net\n",
      "Training Set Results\n",
      "[[17712     0]\n",
      " [14713     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      1.00      0.71     17712\n",
      "         2.0       0.00      0.00      0.00     14713\n",
      "\n",
      "    accuracy                           0.55     32425\n",
      "   macro avg       0.27      0.50      0.35     32425\n",
      "weighted avg       0.30      0.55      0.39     32425\n",
      "\n",
      "Validaton Set Results\n",
      "[[5792    0]\n",
      " [5017    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      1.00      0.70      5792\n",
      "         2.0       0.00      0.00      0.00      5017\n",
      "\n",
      "    accuracy                           0.54     10809\n",
      "   macro avg       0.27      0.50      0.35     10809\n",
      "weighted avg       0.29      0.54      0.37     10809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taaseenali/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (9,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/wwdjpw3x60scvghx_lqvyv440000gp/T/ipykernel_122/2627697039.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learning Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (9,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_layers = [(2), (8), (45), (8, 8), (45, 8), (45, 45), (8, 8, 8), (45, 8, 8), (45, 45, 8)]\n",
    "degree = 2\n",
    "learning_rate = 0.1\n",
    "rmses = []\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "\n",
    "for hidden_layer in hidden_layers:\n",
    "    print(\"Training neural net with hidden layers \", hidden_layer)\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    print(\"Fitting neural net\")\n",
    "    poly_mlp = MLPClassifier(hidden_layer_sizes=hidden_layer, activation='relu', solver='adam', max_iter=1000, learning_rate_init=learning_rate)    \n",
    "    poly_mlp.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    poly_predict_test = poly_mlp.predict(x_poly_train)\n",
    "    poly_predict = poly_mlp.predict(x_poly_test)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    print(\"Training Set Results\")\n",
    "    print(confusion_matrix(y_train, poly_predict_test))\n",
    "    print(classification_report(y_train, poly_predict_test))\n",
    "    \n",
    "    print(\"Validaton Set Results\")\n",
    "    print(confusion_matrix(y_test,poly_predict))\n",
    "    print(classification_report(y_test,poly_predict))\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "    \n",
    "    del poly_features\n",
    "    del x_poly_train\n",
    "    del poly_mlp\n",
    "    del x_poly_test\n",
    "    del poly_predict\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6703b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
