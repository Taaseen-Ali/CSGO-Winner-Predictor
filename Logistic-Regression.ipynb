{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df10e46-3ecd-43b1-9465-28c3591509a8",
   "metadata": {},
   "source": [
    "# CSGO Match Prediction with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c3766f-a685-4de8-9e54-55260aeb09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355d01f-cd67-45d7-8e1b-bc834e266529",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3066d4-c078-4497-a50c-f2f5e1f25e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33cd1b4-a7ac-40cb-b939-404d905ef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index) # Get winner of the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4426f355-9936-459c-9893-a05a88c3e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = [] # Creation of the winners column for the dataset\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69670e7-7527-465b-bb96-33d755fcd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bb54f4-501e-40ff-88bc-c80b07aec1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [ # Rounds we are not parsing, we only care about rounds until halftime\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b596710a-c30b-4819-ba79-52b0d9f898e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c8a893-3b5f-41b2-82ce-c9a0d591c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-072520d650ff>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "<ipython-input-8-072520d650ff>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>_map</th>\n",
       "      <th>1_t1</th>\n",
       "      <th>2_t1</th>\n",
       "      <th>3_t1</th>\n",
       "      <th>4_t1</th>\n",
       "      <th>5_t1</th>\n",
       "      <th>6_t1</th>\n",
       "      <th>7_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>7_winner</th>\n",
       "      <th>8_winner</th>\n",
       "      <th>9_winner</th>\n",
       "      <th>10_winner</th>\n",
       "      <th>11_winner</th>\n",
       "      <th>12_winner</th>\n",
       "      <th>13_winner</th>\n",
       "      <th>14_winner</th>\n",
       "      <th>15_winner</th>\n",
       "      <th>t1_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2533</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2533</td>\n",
       "      <td>571</td>\n",
       "      <td>1</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>28500.0</td>\n",
       "      <td>31900.0</td>\n",
       "      <td>31700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533</td>\n",
       "      <td>571</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>23150.0</td>\n",
       "      <td>21850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>571</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>18050.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>25850.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>27250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>571</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24500.0</td>\n",
       "      <td>27550.0</td>\n",
       "      <td>29350.0</td>\n",
       "      <td>31950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43229</th>\n",
       "      <td>2534</td>\n",
       "      <td>2755</td>\n",
       "      <td>9</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>26750.0</td>\n",
       "      <td>27450.0</td>\n",
       "      <td>26950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43230</th>\n",
       "      <td>236</td>\n",
       "      <td>2873</td>\n",
       "      <td>4</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>17400.0</td>\n",
       "      <td>22050.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>25650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43231</th>\n",
       "      <td>2169</td>\n",
       "      <td>1072</td>\n",
       "      <td>2</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>29150.0</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43232</th>\n",
       "      <td>1705</td>\n",
       "      <td>1065</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>22950.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>26850.0</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43233</th>\n",
       "      <td>2497</td>\n",
       "      <td>2939</td>\n",
       "      <td>8</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43234 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_1  team_2  _map    1_t1     2_t1     3_t1     4_t1     5_t1  \\\n",
       "0        2533     571     0  4350.0   1100.0  22100.0   9350.0  25750.0   \n",
       "1        2533     571     1  3900.0   7400.0  23250.0  28500.0  31900.0   \n",
       "2        2533     571     2  4150.0  14300.0   2000.0  24800.0   9000.0   \n",
       "3         571     236     1  4150.0  18050.0  21000.0  25850.0  25000.0   \n",
       "4         571     236     0  4200.0  10000.0  22000.0  24500.0  27550.0   \n",
       "...       ...     ...   ...     ...      ...      ...      ...      ...   \n",
       "43229    2534    2755     9  4250.0   7400.0  17200.0  18500.0  26750.0   \n",
       "43230     236    2873     4  4250.0   1600.0  24250.0  17400.0  22050.0   \n",
       "43231    2169    1072     2  4350.0   7650.0  20000.0  21500.0  29150.0   \n",
       "43232    1705    1065     2  4150.0  11800.0   1200.0  22950.0  25750.0   \n",
       "43233    2497    2939     8  4100.0  17700.0  18950.0  13200.0  24000.0   \n",
       "\n",
       "          6_t1     7_t1  ...  7_winner  8_winner  9_winner  10_winner  \\\n",
       "0      10400.0  24600.0  ...       2.0       2.0       1.0        2.0   \n",
       "1      31700.0  18950.0  ...       2.0       1.0       1.0        2.0   \n",
       "2      23150.0  21850.0  ...       1.0       2.0       2.0        2.0   \n",
       "3      25000.0  27250.0  ...       1.0       1.0       1.0        1.0   \n",
       "4      29350.0  31950.0  ...       2.0       1.0       1.0        1.0   \n",
       "...        ...      ...  ...       ...       ...       ...        ...   \n",
       "43229  27450.0  26950.0  ...       2.0       1.0       2.0        2.0   \n",
       "43230   6600.0  25650.0  ...       1.0       1.0       1.0        1.0   \n",
       "43231  26900.0   8750.0  ...       2.0       2.0       2.0        1.0   \n",
       "43232  26850.0  27850.0  ...       1.0       1.0       2.0        1.0   \n",
       "43233  20550.0  14500.0  ...       1.0       1.0       1.0        2.0   \n",
       "\n",
       "       11_winner  12_winner  13_winner  14_winner  15_winner  t1_t  \n",
       "0            2.0        2.0        2.0        2.0        2.0     1  \n",
       "1            2.0        2.0        2.0        2.0        2.0     0  \n",
       "2            2.0        2.0        2.0        2.0        2.0     1  \n",
       "3            1.0        1.0        1.0        1.0        1.0     1  \n",
       "4            1.0        1.0        1.0        1.0        1.0     0  \n",
       "...          ...        ...        ...        ...        ...   ...  \n",
       "43229        2.0        2.0        2.0        2.0        2.0     1  \n",
       "43230        1.0        1.0        2.0        2.0        2.0     1  \n",
       "43231        1.0        2.0        2.0        1.0        1.0     0  \n",
       "43232        1.0        1.0        1.0        1.0        1.0     1  \n",
       "43233        1.0        1.0        1.0        1.0        1.0     1  \n",
       "\n",
       "[43234 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc479b72-1d69-4df3-9bac-b85a3f3744d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "43229    2.0\n",
       "43230    1.0\n",
       "43231    1.0\n",
       "43232    1.0\n",
       "43233    1.0\n",
       "Name: match_winner, Length: 43234, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1414a-0b65-4319-845e-32b4c2cfaa86",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb8be17-2722-4233-a204-b5c38fb1c1d6",
   "metadata": {},
   "source": [
    "## One-Hot Conversion (Encoding Teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e67491-ae60-46fd-bd5a-976f9f23b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the team names back into strings again\n",
    "# import gc\n",
    "# num_to_team = dict(zip(range(len(set_of_teams)), set_of_teams))\n",
    "# all_teams = [num_to_team[i] for i in range(len(set_of_teams))]\n",
    "\n",
    "# # Extract the team data from the original DataFrame\n",
    "# team_1_arr = np.array(X[\"team_1\"])\n",
    "# team_2_arr = np.array(X[\"team_2\"])\n",
    "\n",
    "# # Create the one-hot vectors for each row of the data, one for each team\n",
    "# one_hot_t1 = np.zeros((team_1_arr.size, len(num_to_team)))\n",
    "# one_hot_t1[np.arange(team_1_arr.size), team_1_arr] = 1\n",
    "\n",
    "# one_hot_t2 = np.zeros((team_2_arr.size, len(num_to_team)))\n",
    "# one_hot_t2[np.arange(team_2_arr.size), team_2_arr] = 1\n",
    "\n",
    "# # Combine the matrix of one-hot vectors for team_1 and team_2 together to create a single matrix\n",
    "# one_hot = np.hstack((one_hot_t1, one_hot_t2))\n",
    "\n",
    "# # Turn the numpy array into a pandas DataFrame and add it to the dataset\n",
    "# one_hot_df = pd.DataFrame(one_hot, columns = [\"team_1_%s\" %(i) for i in all_teams] + [\"team_2_%s\" %(i) for i in all_teams])\n",
    "# X = X.drop(columns = [\"team_1\", \"team_2\"])\n",
    "# X = X.join(one_hot_df)\n",
    "# # Freeing memory for training and test dataset splits\n",
    "# del team_1_arr\n",
    "# del team_2_arr\n",
    "# del num_to_team\n",
    "# del all_teams \n",
    "# del one_hot_t1\n",
    "# del one_hot_t2\n",
    "# del one_hot\n",
    "# del one_hot_df\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bf600-5b52-4c54-84c7-b2aa15ed8cff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59aed415-2eab-4e7e-aed0-e170fd855334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a5eef-ed81-47a7-9c64-9d633d677c5c",
   "metadata": {},
   "source": [
    "## LogReg w/ No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c32b784-1f9b-4d3d-8b8b-c593f86a5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_none = linear_model.LogisticRegression(penalty='none') # No regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2014dae8-a990-40ee-8194-cff676aeaa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_none.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13ac3b4-084e-4cfc-bef1-53ea9f1d019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.775050\n",
      "Accuracy on test data = 0.776668\n"
     ]
    }
   ],
   "source": [
    "yhat_train = logreg_ridge_none.predict(X_train)\n",
    "yhat = logreg_ridge_none.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat == y_test)\n",
    "acc_train = np.mean(yhat_train == y_train)\n",
    "print(\"Accuracy on training data = %f\" % acc_train)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f341d4d7-7885-4aac-a1fa-ed7e3ffd3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 1.0\n",
      "Accuracy on the test data is 0.776668\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>-0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>-0.008742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.029645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.050898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>-0.029815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.047879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.021732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.018659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>-0.003963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>0.004727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>-0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.013184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.020607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.061991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.015179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.025561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>-0.015348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.034239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.023654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>-0.006056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.007970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>-0.011619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>-0.017019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.012124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>-0.005043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.012316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>-0.028159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.023930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.229827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.265785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.215320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.273051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.317482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.272801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.296858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.297006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.284546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.272343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.289665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.290774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.267096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.264346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.290255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.122242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1  0.001003\n",
       "1      team_2 -0.000882\n",
       "2        _map -0.008742\n",
       "3    t1_start  0.029645\n",
       "4        1_t1 -0.050898\n",
       "5        2_t1 -0.029815\n",
       "6        3_t1 -0.047879\n",
       "7        4_t1  0.005702\n",
       "8        5_t1  0.002683\n",
       "9        6_t1  0.021732\n",
       "10       7_t1 -0.018659\n",
       "11       8_t1 -0.003963\n",
       "12       9_t1  0.004727\n",
       "13      10_t1  0.003102\n",
       "14      11_t1 -0.000494\n",
       "15      12_t1 -0.013184\n",
       "16      13_t1 -0.020607\n",
       "17      14_t1 -0.061991\n",
       "18      15_t1  0.015179\n",
       "19       1_t2  0.025561\n",
       "20       2_t2 -0.015348\n",
       "21       3_t2  0.034239\n",
       "22       4_t2  0.023654\n",
       "23       5_t2 -0.006056\n",
       "24       6_t2  0.007970\n",
       "25       7_t2 -0.011619\n",
       "26       8_t2 -0.017019\n",
       "27       9_t2  0.012124\n",
       "28      10_t2 -0.005043\n",
       "29      11_t2  0.012316\n",
       "30      12_t2 -0.028159\n",
       "31      13_t2  0.023930\n",
       "32      14_t2  0.017506\n",
       "33      15_t2  0.229827\n",
       "34   1_winner  0.265785\n",
       "35   2_winner  0.215320\n",
       "36   3_winner  0.273051\n",
       "37   4_winner  0.317482\n",
       "38   5_winner  0.272801\n",
       "39   6_winner  0.296858\n",
       "40   7_winner  0.297006\n",
       "41   8_winner  0.284546\n",
       "42   9_winner  0.272343\n",
       "43  10_winner  0.289665\n",
       "44  11_winner  0.290774\n",
       "45  12_winner  0.267096\n",
       "46  13_winner  0.264346\n",
       "47  14_winner  0.290255\n",
       "48  15_winner -0.122242"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_none.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_none.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48c219c-bcec-439a-8536-6784f2326e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4597, 1219],\n",
       "       [1195, 3798]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "463a3448-5b93-43ea-9ce2-82b90d5d2f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750 (0.007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_none, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31dcf236-c624-4cd7-9e6e-8f364706842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7904057771664375\n",
      "recal:  0.7936809392265194\n",
      "fscore:  0.792039972432805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b26bf-8f1b-4c77-a5c4-2098bf1e519f",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4238f27d-d1c3-4953-87b7-f0816e9838e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l1 = linear_model.LogisticRegression(solver='liblinear', penalty='l1',warm_start=True, C = 0.001) # L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28d564e0-74fe-43b5-8d02-d8ac2edd6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='l1', solver='liblinear', warm_start=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5af83e63-6336-4469-812c-5e34f23adcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.776945\n"
     ]
    }
   ],
   "source": [
    "yhat_l1 = logreg_ridge_l1.predict(X_test) # the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l1 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f84406b-90e7-4af7-a091-2931d5b4a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 0.001\n",
      "Accuracy on the test data is 0.776945\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.035007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.090673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.228445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.176333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.152752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.212140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.157844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.188272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.181949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.179867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.169138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.186302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.181095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.175119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.163115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.133858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1  0.000000\n",
       "1      team_2  0.000000\n",
       "2        _map  0.000000\n",
       "3    t1_start  0.000000\n",
       "4        1_t1  0.000000\n",
       "5        2_t1  0.000000\n",
       "6        3_t1  0.000000\n",
       "7        4_t1  0.000000\n",
       "8        5_t1  0.000000\n",
       "9        6_t1  0.000000\n",
       "10       7_t1  0.000000\n",
       "11       8_t1  0.000000\n",
       "12       9_t1  0.000000\n",
       "13      10_t1  0.000000\n",
       "14      11_t1  0.000000\n",
       "15      12_t1  0.000000\n",
       "16      13_t1  0.000000\n",
       "17      14_t1 -0.035007\n",
       "18      15_t1  0.000000\n",
       "19       1_t2  0.000000\n",
       "20       2_t2  0.000000\n",
       "21       3_t2  0.000000\n",
       "22       4_t2  0.000000\n",
       "23       5_t2  0.000000\n",
       "24       6_t2  0.000000\n",
       "25       7_t2  0.000000\n",
       "26       8_t2  0.000000\n",
       "27       9_t2  0.000000\n",
       "28      10_t2  0.000000\n",
       "29      11_t2  0.000000\n",
       "30      12_t2  0.000000\n",
       "31      13_t2  0.000000\n",
       "32      14_t2  0.000000\n",
       "33      15_t2  0.090673\n",
       "34   1_winner  0.228445\n",
       "35   2_winner  0.176333\n",
       "36   3_winner  0.152752\n",
       "37   4_winner  0.212140\n",
       "38   5_winner  0.157844\n",
       "39   6_winner  0.188272\n",
       "40   7_winner  0.181949\n",
       "41   8_winner  0.179867\n",
       "42   9_winner  0.169138\n",
       "43  10_winner  0.186302\n",
       "44  11_winner  0.181095\n",
       "45  12_winner  0.175119\n",
       "46  13_winner  0.163115\n",
       "47  14_winner  0.133858\n",
       "48  15_winner  0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l1.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l1.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7289d95-1ac7-4d27-813d-6b11f28c0d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4513, 1132],\n",
       "       [1279, 3885]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65b3571-64c7-430d-8244-b46b762439cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.753 (0.008)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5da29ead-ec78-441e-816c-eb2ae6aab8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7994685562444641\n",
      "recal:  0.7791781767955801\n",
      "fscore:  0.789192970184489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l1,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebee315-c6f4-497d-9e04-be0d284225ac",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dad92fd-ca5e-40ed-8a06-f1bdabc32ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l2 = linear_model.LogisticRegression(penalty='l2', C = 0.001) # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4ddd862-b81a-444c-9b19-a44ffcb47051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a11e5edf-096b-4ef2-9785-de3a0d51af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.774725\n"
     ]
    }
   ],
   "source": [
    "yhat_l2 = logreg_ridge_l2.predict(X_test) # the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l2 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a63a024e-0ae7-4663-974d-7abe2f4507bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 0.001\n",
      "Accuracy on the test data is 0.774725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>-0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>-0.005335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.026863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.096945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>-0.071344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.061719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>-0.035099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>-0.042614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>-0.025117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.053497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>-0.044619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>-0.035818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>-0.036506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>-0.043355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.052182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.052546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.082281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.008145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.091633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>0.045809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.056495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.056569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>0.036995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.045295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>0.030169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>0.028882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.046730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>0.034527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.051057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>0.020420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.057020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.049667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.128058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.157651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.154229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.187361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.208650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.179406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.198440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.195081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.189632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.182198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.194556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.196742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.186233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.193199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.235382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.179129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1  0.000238\n",
       "1      team_2 -0.000570\n",
       "2        _map -0.005335\n",
       "3    t1_start  0.026863\n",
       "4        1_t1 -0.096945\n",
       "5        2_t1 -0.071344\n",
       "6        3_t1 -0.061719\n",
       "7        4_t1 -0.035099\n",
       "8        5_t1 -0.042614\n",
       "9        6_t1 -0.025117\n",
       "10       7_t1 -0.053497\n",
       "11       8_t1 -0.044619\n",
       "12       9_t1 -0.035818\n",
       "13      10_t1 -0.036506\n",
       "14      11_t1 -0.043355\n",
       "15      12_t1 -0.052182\n",
       "16      13_t1 -0.052546\n",
       "17      14_t1 -0.082281\n",
       "18      15_t1  0.008145\n",
       "19       1_t2  0.091633\n",
       "20       2_t2  0.045809\n",
       "21       3_t2  0.056495\n",
       "22       4_t2  0.056569\n",
       "23       5_t2  0.036995\n",
       "24       6_t2  0.045295\n",
       "25       7_t2  0.030169\n",
       "26       8_t2  0.028882\n",
       "27       9_t2  0.046730\n",
       "28      10_t2  0.034527\n",
       "29      11_t2  0.051057\n",
       "30      12_t2  0.020420\n",
       "31      13_t2  0.057020\n",
       "32      14_t2  0.049667\n",
       "33      15_t2  0.128058\n",
       "34   1_winner  0.157651\n",
       "35   2_winner  0.154229\n",
       "36   3_winner  0.187361\n",
       "37   4_winner  0.208650\n",
       "38   5_winner  0.179406\n",
       "39   6_winner  0.198440\n",
       "40   7_winner  0.195081\n",
       "41   8_winner  0.189632\n",
       "42   9_winner  0.182198\n",
       "43  10_winner  0.194556\n",
       "44  11_winner  0.196742\n",
       "45  12_winner  0.186233\n",
       "46  13_winner  0.193199\n",
       "47  14_winner  0.235382\n",
       "48  15_winner -0.179129"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l2.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l2.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "035b2543-26f2-4f57-bf4d-cb0d0af5e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4645, 1288],\n",
       "       [1147, 3729]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4674da8-cff6-417c-a812-b1f8548b6075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750 (0.007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l2, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ab06ab-c282-4f0d-a763-6d4040591692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7829091521995618\n",
      "recal:  0.8019682320441989\n",
      "fscore:  0.7923240938166312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l2,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd8a5f-5d37-4bb5-99ba-29caa7c434d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5b07f-17bc-4736-b0cd-2c7afab7d2c6",
   "metadata": {},
   "source": [
    "## Polynomial Transformation Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9d5fa31-5713-4d9b-ad98-c503025097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful polynomial library\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568dfaf7-851c-4727-9fe9-d55fa758387f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae95368a-5c3f-4df5-88b6-79d8055a9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a4fa4b2-0bca-443c-8348-455db8e901b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe1c8e8-f48b-4df9-b1df-56aef0a46955",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = []\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caf7cdd5-1e31-4e50-9b3c-cdbc1b4b428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f8edd54-e052-4026-8f0d-79fb6cc5b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)\n",
    "df = df.sample(frac = .55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a7d1f32-0106-4ebb-b029-6b371de8506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "124e78bb-2326-4381-b9db-50faea7a8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-9df4de8fea1f>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "<ipython-input-40-9df4de8fea1f>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18c8f983-5ed4-4c5b-b8d5-0c4de3b641f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3981e86-6482-478b-bc26-83d6f3a7c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Deg:  1\n",
      "Predict Deg:  1\n",
      "Training Set Results\n",
      "[[7760 1940]\n",
      " [2051 6083]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.80      0.80      9700\n",
      "         2.0       0.76      0.75      0.75      8134\n",
      "\n",
      "    accuracy                           0.78     17834\n",
      "   macro avg       0.77      0.77      0.77     17834\n",
      "weighted avg       0.78      0.78      0.78     17834\n",
      "\n",
      "[[2603  635]\n",
      " [ 702 2005]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.80      0.80      3238\n",
      "         2.0       0.76      0.74      0.75      2707\n",
      "\n",
      "    accuracy                           0.78      5945\n",
      "   macro avg       0.77      0.77      0.77      5945\n",
      "weighted avg       0.77      0.78      0.77      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\justin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Deg:  2\n",
      "Predict Deg:  2\n",
      "Training Set Results\n",
      "[[7997 1703]\n",
      " [1868 6266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.82      0.82      9700\n",
      "         2.0       0.79      0.77      0.78      8134\n",
      "\n",
      "    accuracy                           0.80     17834\n",
      "   macro avg       0.80      0.80      0.80     17834\n",
      "weighted avg       0.80      0.80      0.80     17834\n",
      "\n",
      "[[2561  677]\n",
      " [ 740 1967]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.79      0.78      3238\n",
      "         2.0       0.74      0.73      0.74      2707\n",
      "\n",
      "    accuracy                           0.76      5945\n",
      "   macro avg       0.76      0.76      0.76      5945\n",
      "weighted avg       0.76      0.76      0.76      5945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\justin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Deg:  3\n",
      "Predict Deg:  3\n",
      "Training Set Results\n",
      "[[9690   10]\n",
      " [  13 8121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00      9700\n",
      "         2.0       1.00      1.00      1.00      8134\n",
      "\n",
      "    accuracy                           1.00     17834\n",
      "   macro avg       1.00      1.00      1.00     17834\n",
      "weighted avg       1.00      1.00      1.00     17834\n",
      "\n",
      "[[2345  893]\n",
      " [ 907 1800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.72      0.72      3238\n",
      "         2.0       0.67      0.66      0.67      2707\n",
      "\n",
      "    accuracy                           0.70      5945\n",
      "   macro avg       0.69      0.69      0.69      5945\n",
      "weighted avg       0.70      0.70      0.70      5945\n",
      "\n",
      "Best degree 1 with RMSE 0.4742308189461663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEGCAYAAADFWoruAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwJUlEQVR4nO3deXyV5Z338c+XEJawBAj7TgBRQAUMIbjUpdWiQulYdwRllU5trR2fjnac+rR1plOnT1etFAFxRcRq61aXTp1aWwgkCLJrCCCJYiSBsC9Jfs8f54aGY0JyICf3SfJ7v1555Zz7vs51vud4k5/XvV0yM5xzzrlE0CzsAM4559wxXpScc84lDC9KzjnnEoYXJeeccwnDi5JzzrmE0TzsAA1Z586drX///mHHcM65BiU3N3enmXWpap0XpdPQv39/cnJywo7hnHMNiqRt1a3z3XfOOecShhcl55xzCcOLknPOuYThRck551zC8KLknHMuYXhRcs45lzC8KEWRlC5pvqTnw87inHNNTVyLkqStktZIWiWpygt6atMmhvdbIKlI0tqo5eMkbZKUJ+mek/VhZvlmNv10cjjnXGP26Dv55G4riUvf9TFSutTMRphZxqm0kdRVUruoZYOq6WchMC6qbRLwMHAlMBS4SdLQYN3Zkl6J+ula+4/mnHNNy/x3t/Afr23g+dzCuPTfEO7ocDEwW9JVZnZY0kzgGiJF5gRm9o6k/lGLM4E8M8sHkPQsMBFYb2ZrgPGxBpI0AZgwaFB1tdE55xqfRcs/4kevrOfK4d350cRhcXmPeI+UDHhTUq6kWafSxsyWAG8AiyVNAqYB18WQoRewvdLzgmBZlSSlSZoDjJR0b5WBzV42s1mpqakxxHDOuYbrxfcK+N6La7h0SBd+eeNImifFp3zEe6R0oZkVBrvE3pK00czeibWNmT0YjHAeAQaa2b54BTazYmB2vPp3zrmG5vW1n3D3kvcZm57GI7ecR4vm8RvPxHWkZGaFwe8i4EUiu9JibiPpImB4sP7+GGMUAn0qPe8dLHPOOVeDtzcW8c1F7zGiTwcenZJBq+SkuL5f3IqSpDbHTlCQ1Aa4Aog+K642bUYCc4kcB5oKpEl6IIYoK4DBkgZIagHcCLx0ap/KOeeajr9v3snsp3IZ0r0dj00dTZuW8T8NIZ4jpW7Au5JWA8uBV83sdQBJr0nqebI2laQA15vZZjOrAKYAVd72XNIiYCkwRFKBpOlmVgbcQeS41AbgOTNbV+ef1jnnGpHcbSXMeDyHfmkpPDFtDO1bJdfL+8rM6uWNGqOMjAzz+ZScc43N2sJSbpq7jM7tWrL49iy6tmtVp/1Lyq3uMiG/o4NzzrnjNu3Yy+T52bRvnczTM8bUeUGqiRcl55xzAGzZuZ9J87Jp0bwZz8wcQ88Ores9Q0O4eNY551ycFew6wKRHl1FhxrMzsuiX1iaUHD5Scs65Ju7TPYe4+dFs9h0u48npmQzq2q7mF8WJFyXnnGvCivcdZtK8bIr3HebxaZkM6xnunWp8951zzjVRpQeOcsv85RTsOsDCqZmM7Nsx7Eg+UnLOuaZo3+Eybn1sOZuL9vHbyRlkpaeFHQnwkZJzzjU5B4+UM23hCtYUlvLIpFFcfEaXsCMd5yMl55xrQg6XlTPryRxWbC3hZ9efyxXDuocd6QRelJxzrok4Wl7BHc+8x18/3MlPrjmHiSOqncUnNF6UnHOuCSivML7z3GreWv8pP/jKMK4f3afmF4XAi5JzzjVyFRXGvS+8z8urP+Zfx53Jref3DztStbwoOedcI2Zm/ODldTyXU8C3LhvE1y8ZGHakk/Ki5JxzjZSZ8ZPXN/H40m3MuHAAd11+RtiRauRFKYqkdEnzJT0fdhbnnDsdv/5zHnP+splJY/ryb1efhaSwI9UorkVJ0lZJayStklTtxEOSkiS9J+mV03y/BZKKJEXPXjtO0iZJeZLuOVkfZpZvZtNPJ4dzzoVt3l/z+dlbH3DNqF78aOLwBlGQoH5GSpea2YjqJnQK3ElkVtjPkdT12JTplZYNqqafhcC4qLZJwMPAlcBQ4CZJQ4N1Z0t6Jeqna60+lXPOJainlm3jgVc3cPXZPXjwa+fQrFnDKEiQALvvJPUGrgbmVdPkYuD3kloG7WcCv66qoZm9A5RELc4E8oIR0BHgWWBi0H6NmY2P+imqReYJkuaWlpbW5iM651y9eWFlAf/+h7VcdmZXfn7DCJonhf5nPibxTmvAm5JyJc2qps0vgO8CFVV2YLYEeANYLGkSMA24LoYMvYDtlZ4XBMuqJClN0hxgpKR7q8n0spnNSk0N9266zjlX2WtrPuHuJas5f2Aav5k0ihbNG1ZBgvjf++5CMysMdom9JWljMJoBQNJ4oMjMciVdUl0nZvagpGeBR4CBZrYvXoHNrBiYHa/+nXMuHv688VO+teg9RvXtyKNTMmiVnBR2pFMS1zJqZoXB7yLgRSK70iq7APiKpK1EdqtdJump6H4kXQQMD/q4P8YYhUDlS5d7B8ucc65R+FveTmY/tZKhPduzYOpoUlo03Httx60oSWpz7AQFSW2AK4ATzoozs3vNrLeZ9QduBP5sZrdE9TMSmEvkONBUIE3SAzFEWQEMljRAUovgfV46xY/lnHMJJWdrCTMez2FAWhsen5pJ+1bJYUc6LfEcKXUD3pW0GlgOvGpmrwNIek1Sz1r2kwJcb2abzawCmAJsq6qhpEXAUmCIpAJJ082sDLiDyHGpDcBzZrbutD6Zc84lgPcLdjP1sRX0SG3FUzPG0LFNi7AjnTaZWdgZGqyMjAzLyan28ivnnIubjTv2cOPcZbRt2Zwls8fSI7V12JFqTVJudZcJNbxTM5xzronL/2wft8xbTqvmSTwzI6tBFaSaeFFyzrkGZHvJASbNy8bMeGrGGPqmpYQdqU413FM0nHOuidlReoib5y3jwJFynp2VxaCubcOOVOd8pOSccw3Azn2HmTRvGbv2H+XxaZmc1aN92JHiwouSc84luN0HjnDLvGwKdx9kwW2jGdGnQ9iR4saLknPOJbC9h45y64Ll5H+2n0enZJA5oFPYkeLKi5JzziWoA0fKmL4wh3Uf7+HhSaO4aHCXsCPFnRcl55xLQIeOlnP7k7nkbCvh5zeM4PKh3cKOVC/87DvnnEswR8sruOOZlfz1w53897XnMOHc2t4Ap+HzkZJzziWQ8grjrsWr+NOGIn40cRjXZfSp+UWNiBcl55xLEBUVxr/+7n1eef8T7r3yTCaP7R92pHrnRck55xKAmXH/S+t4PreAO784mNsvHhh2pFB4UXLOuZCZGf/1x408uWwbs76Qzre/NDjsSKHxouSccyH75f98yG/fyWdyVj/uvfJMJIUdKTRelJxzLkRz39nML/70Idee15sffGVYky5I4EXpcySlS5ov6fmwszjnGrcnl27lP1/byNXn9OAnXzuHZs2adkGCOBclSVslrZG0StLnZsOT1ErSckmrJa2T9IPTfL8FkookrY1aPk7SJkl5ku45WR9mlm9m008nh3PO1WRJznb+/Q/r+NJZXfnFDSNI8oIE1M9I6VIzG1HNLIOHgcvM7FxgBDBOUlblBpK6SmoXtWxQNe+1EBgX1TYJeBi4EhgK3CRpaLDubEmvRP10jf0jOudc7b28+mP+9Xfvc9Hgzjx08yiSk3yn1TGh3tHBInOx7wueJgc/0fOzXwzMlnSVmR2WNBO4hkiRie7vHUn9oxZnAnlmlg8g6VlgIrDezNYA42PNLWkCMGHQoOpqo3POVe1P6z/lrsWrOK9fR347+TxaJSeFHSmhxLs8G/CmpFxJs6pqIClJ0iqgCHjLzLJP6MBsCfAGsFjSJGAacF0MGXoB2ys9LwiWVUlSmqQ5wEhJ91bVxsxeNrNZqampMcRwzjV17364k39+eiXDerZnwW2jSWnhd3qLFu9v5EIzKwx2ib0laaOZvVO5gZmVAyMkdQBelDTczNZGtXkwGOE8Agw0s33EiZkVA7Pj1b9zrmlasbWEmU/kkN6lDY9Py6Rdq+SwIyWkuI6UzKww+F0EvEhkV1p1bXcDbxN1TAhA0kXA8KCP+2OMUQhUvnlU72CZc87Vi9XbdzP1sRX06NCKp2aMoUNKi7AjJay4FSVJbY6doCCpDXAFEH1WXJdghISk1sDlwMaoNiOBuUSOA00F0iQ9EEOUFcBgSQMktQBuBF46pQ/lnHMx2vDJHqYsWE7HNsk8MyOLzm1bhh0pocVzpNQNeFfSamA58KqZvQ4g6TVJPYEewNuS3idSPN4ys1ei+kkBrjezzWZWAUwBtlX1hpIWAUuBIZIKJE03szLgDiLHpTYAz5nZujr/tM45FyWvaB+T52eT0iKJZ2Zk0T21VdiREp4iJ8C5U5GRkWE5OZ+7/Mo559hecoDr5iylrKKCxbePZWCXtmFHShiScqu5TMgn+XPOubr2SelBbnp0GYfKynl2VpYXpBj4FVvOOVeHPtt7mEmPZrP7wFGemJbJmd3bhx2pQfGi5JxzdWTX/iNMnp/NJ6WHeGzqaM7p3SHsSA2O775zzrk6sOfQUW59bDn5O/ez4NbRjO7fKexIDZKPlJxz7jQdOFLGtMdWsP7jPTwyaRQXDu4cdqQGy4uSc86dhkNHy5n1RC4rP9rFL28cyRfP6hZ2pAbNd98559wpOlJWwTeeXsm7eTv56XXncvU5PcKO1OD5SMk5505BWXkFdy1exf9sLOJHXx3Otef1DjtSo+BFyTnnYlRRYXz3d+/z6ppP+LerzmJyVr+wIzUaXpSccy4GZsa//2EtL6ws5K4vncHML6SHHalR8aLknHO1ZGb852sbeDr7I26/OJ1vfdEn+qxrXpScc66Wfv6nD3n0r1u4dWw/7hl3JpLCjtToeFFyzrlamPOXzfzqfz7kuvN6c/+EYV6Q4sSLknPO1eDxv2/lv/64kQnn9uS/vnYOzZp5QYoXL0rOOXcSz63Yzv0vrePyod342fXnkuQFKa68KFVBUrqk+ZKeDzuLcy48L63+mH994X0uGtyZh24eSXKS/8mMt7h/w5K2SlojaZWkz82IJ6mPpLclrZe0TtKdp/FeCyQVSVpbxbpxkjZJypN0z8n6MbN8M5t+qjmccw3fm+t2cNfiVYzu34m5kzNo2Twp7EhNQn3dZuhSM9tZzboy4F/MbKWkdkCupLfMbP2xBpK6AgfNbG+lZYPMLC+qr4XAQ8ATlRdKSgIeBi4HCoAVkl4CkoAfR/UxzcyKYv6EzrlG4y8ffMYdz7zH8F6pLLhtNK1beEGqL6GPRc3sEzNbGTzeC2wAekU1uxj4vaSWAJJmAr+uoq93gJIq3iYTyAtGQEeAZ4GJZrbGzMZH/dRYkCRNkDS3tLQ0lo/qnGsAsvOLuf3JHAZ2bcsTUzNp29JvEVqf6qMoGfCmpFxJs07WUFJ/YCSQfUIHZkuAN4DFkiYB04DrYsjQC9he6XkBny98lXOkSZoDjJR0b/R6M3vZzGalpqbGEME5l+hWbd/NtIUr6NWhNU9OzyQ1JTnsSE1OffwvwIVmVhjsgntL0sZgRHMCSW2B3wHfNrM90evN7EFJzwKPAAPNbF+8AptZMTA7Xv075xLP+o/3MGV+NmltW/L0jCw6t20ZdqQmKe4jJTMrDH4XAS8S2ZV2AknJRArS02b2QlX9SLoIGB70cX+MMQqBPpWe9w6WOecceUV7mTw/m7Ytm/P0jDF0T20VdqQmK65FSVKb4OQFJLUBrgDWRrURMB/YYGY/q6afkcBcYCIwFUiT9EAMUVYAgyUNkNQCuBF4KdbP45xrfLYV72fSvGwk8dSMMfTplBJ2pCYt3iOlbsC7klYDy4FXzex1AEmvSeoJXABMBi4LThtfJemqqH5SgOvNbLOZVQBTgG3RbyZpEbAUGCKpQNJ0ADMrA+4gclxqA/Ccma2Lxwd2zjUcH+8+yM2PZnOkrIKnZ4whvUvbsCM1eTKzsDM0WBkZGZaT87lLr5xzDUDR3kPc8Ntl7Nx7mGdmZnF2bz9xqb5IyjWzjKrW+bmOzrkmZ9f+I0yet5xP9xziyemZXpASiBcl51yTsufQUaYsWM6W4v0svG005/XrFHYkV0noF88651x92X+4jKmPrWDjjj3MuWUU5w/qHHYkF8WLknOuSTh0tJyZT+Tw3ke7+OWNI7nszG5hR3JV8N13zrlG70hZBV9/Kpel+cX8v+vO5aqze4QdyVXDR0rOuUatrLyCO599j7c3fcYDXx3ONaN6hx3JncRJi5Kkyyo9HhC17pp4hXLOubpQUWF89/n3+ePaHdx39VlMGtMv7EiuBjWNlH5a6fHvotbdV8dZnHOuzpgZ9/1hLS+8V8i/XH4GMy5KDzuSq4WaipKqeVzVc+ecSwhmxgOvbuCZ7I/4+iUDueOyQWFHcrVUU1Gyah5X9dw55xLCz976gPnvbuG28/vz3S8PIXKLTdcQ1HT2XXowQ6sqPSZ4PqD6lznnXDh+8795/PrPedyQ0Yfvjx/qBamBqakoTaz0+KdR66KfO+dcqB772xYefH0TE0f05D+vOZtmzbwgNTQnLUpm9pfKz4N5j4YDhbWZNtw55+rL4hUf8YOX13PF0G789LpzSfKC1CDVdEr4HEnDgsepwGrgCeA9STfVQz7nnKvRH1YVcs8La7j4jC78+uaRJCf5JZgNVU3/5S6qNO/QVOADMzsbOA/4blyTOedcLby+dgffeW41mf07MeeW82jZPCnsSO401FSUjlR6fDnwewAz2xGvQM45V1v/u6mIby5ayTm9U5l/22hat/CC1NDVVJR2SxofTEd+AXBs1tjmQOt4hwuDpHRJ8yU9H3YW51z1lm4u5vYncxnctR0Lp2bStqXfyrMxqKko3U5kGvHHgG9XGiF9EXi1ps4lbZW0JpjivMopWiUtkFQkaW0swWPpS9I4SZsk5Um652R9mFm+mU0/3SzOufhZ+dEupj++gr6dUnhyeiaprZPDjuTqSE1n330AjKti+RvAG7V8j0vNbOdJ1i8EHiJyAsXnSOoKHDSzvZWWDTKzvNr0JSkJeJjI7scCYIWkl8xsvaSzgR9H9THNzyx0LnGtLSzl1gXL6dKuJU/PGENa25ZhR3J16KRFSdKvTrbezL51ugHM7B1J/U/S5GJgtqSrzOywpJnANcCVtewrE8gzs3wASc8Suf5qvZmtAcbHmlnSBGDCoEF+6xLn6tOHn+5lyoLltGvZnKdnjKFr+1ZhR3J1rKbdd7OBC4GPgRwgN+qnJga8KSlX0qxTCWhmS4iMyhZLmgRMA66LoYtewPZKzwuCZVWSlCZpDjBS0r3VZHrZzGalpqbGEMM5dzq27tzPpHnZJDUTz8zMonfHlLAjuTio6chgDyIF4AagDFgMPG9mu2vZ/4VmVhjsgntL0kYzeyfWkGb2YDDCeQQYaGb7Yu0jhvcqJlKMnXMJonD3QSbNy+ZoeQWLbx9L/85two7k4uSkIyUzKzazOWZ2KZHrlDoA6yVNrk3nZlYY/C4CXiSyKy1mki4icieJF4H7Y3x5IdCn0vPewTLnXANQtOcQkx5dxp5DR3ly+hjO6NYu7Egujmp12bOkUcCdwC3AH6nFrjtJbSS1O/YYuAKI+Qy74HT0uUSOA00F0iQ9EEMXK4DBkgZIagHcCLxUw2uccwmgZP8RJs3LpmjvYRZOzWR4L99l3tjVdJuhH0rKBb4D/AXIMLPpZra+Fn13A96VtBpYDrxqZseuc3pNUs/g8SJgKTBEUoGk6NOxU4DrzWyzmVUAU4Bt1eT9XF9mVkbktPY3gA3Ac5XuUuGcS1ClB48yeX42H5UcYP6tozmvX8ewI7l6ILPqp0WSVAFsAQ4Ei441FmBmdk584yW2jIwMy8mp8vIr59xp2H+4jMnzs1lTWMrcKRlcOqRr2JFcHZKUa2YZVa2r6UQHnzPJOVevDh0tZ8bjOawuKOXhm0d6QWpiarp4trrdZM2Am6hmN5pzzp2Kw2XlzH4ql2Vbivn59SMYN7xH2JFcPavpmFJ7SfdKekjSFYr4JpAPXF8/EZ1zTUFZeQV3LlrF/276jP/8p7P56shqLyd0jVhNu++eBHYROXlgBvA9IseTvmpmq+IbzTnXVJRXGHcvWc3r63bw/fFDuSmzb9iRXEhqKkrpwfxJSJoHfAL0NbNDcU/mnGsSzIz7fr+G36/6mP/z5SFMu9APZTdlNV2ndPTYAzMrBwq8IDnn6oqZ8cNX1rNo+Xa+celAvnGp30+yqatppHSupD3BYwGtg+fHTglvH9d0zrlG7advbuKxv21l6gX9ufuKIWHHcQmgprPvfBpH51xcPPx2Hg+/vZmbMvvw/fFDkRR2JJcAanWbIeecq0vz393Cf7+xia+O6MkDXz3bC5I7zouSc65eLVr+ET96ZT3jhnXnp9edS1IzL0juH7woOefqzYvvFfC9F9dwyZAu/OqmkTRP8j9B7kS+RTjn6sXraz/h7iXvkzUgjTm3nEeL5v7nx32ebxXOubh7e2MR31z0Huf2TmXerRm0SvZzqFzVvCg55+Lq75t3MvupXIZ0b8djUzNp07KmK1FcU+ZFyTkXN7nbSpjxeA790lJ4YtoYUlsnhx3JJTgvSs65uFhbWMptC1bQtV1Lnpo+hk5tWoQdyTUAXpSqICld0nxJz4edxbmGaNOOvUyen0371sk8PTOLru1bhR3JNRAJUZQkbZW0RtIqSac8laukBZKKJK2tYt04SZsk5Um652T9mFm+mUVPy+6cq4UtO/dzy/xskpOa8czMMfTq0DrsSK4BSaQjjpea2c6qVkjqChw0s72Vlg0ys7yopguBh4Anol6fBDwMXA4UACskvQQkAT+O6mOamRWdzgdxrqkq2HWASY8uo7zCWDwri35pbcKO5BqYRCpKJ3MxMFvSVWZ2WNJM4BrgysqNzOwdSf2reH0mkGdm+QCSngUmmtmPgfHxje5c0/DpnkNMmpfNvsNlLJqVxeBu7cKO5BqghNh9BxjwpqRcSbM+t9JsCfAGsFjSJGAacF0M/fcCtld6XhAsq5KkNElzgJGS7q1i/QRJc0tLS2OI4FzjVbzvMJPmZbNz72Een5bJsJ6pYUdyDVSijJQuNLPCYDfdW5I2mtk7lRuY2YPBCOcRYKCZ7YtXGDMrBmafZP3LwMsZGRkz45XBuYai9MBRJs9fTsGuAyycmsnIvh3DjuQasIQYKZlZYfC7CHiRyO62E0i6CBgerL8/xrcoBPpUet47WOacOw37Dpdx62PLySvax28nZ5CVnhZ2JNfAhV6UJLWR1O7YY+AKYG1Um5HAXGAiMBVIk/RADG+zAhgsaYCkFsCNwEt1kd+5purgkXKmL1zBmsJSfn3zSC4+o0vYkVwjEHpRAroB70paDSwHXjWz16PapADXm9lmM6sApgDbojuStAhYCgyRVCBpOoCZlQF3EDkutQF4zszWxe0TOdfIHS4r5/anclm+tYSfXX8uXx7WPexIrpGQmYWdocHKyMiwnJxTvqzKuQbpaHkF33h6JW+u/5SffO1sbhjdN+xIroGRlGtmGVWtS4SRknOugSivMP7ludW8uf5T/u+EoV6QXJ3zouScq5WKCuN7L6zhpdUf891xQ7jtggFhR3KNkBcl51yNzIwfvrKexTnb+eZlg/jnSwaFHck1Ul6UnHMnZWY8+MYmFv59K9MvHMB3Lj8j7EiuEfOi5Jw7qYf+nMcj/7uZm8f05b6rz0JS2JFcI+ZFyTlXrXl/zef/vfUB14zsxQMTh3tBcnHnRck5V6Wns7fxwKsbuOrs7jx47Tk0a+YFycWfFyXn3Oe8sLKA+36/lsvO7MovbhhJ8yT/U+Hqh29pzrkTvLbmE+5espqx6Wn8ZtIoWjT3PxOu/vjW5pw77s8bP+Vbi95jZN+OPDolg1bJSWFHck2MFyXnHAB/y9vJ7KdWclaP9jw2dTRtWibKzDauKfGi5JwjZ2sJMx7PYUBaG56Ylkn7VslhR3JNlBcl55q49wt2M/WxFfRIbcWTMzLp2KZF2JFcE+ZFybkmbOOOPUxZsJz2rZN5asYYurZrFXYk18R5UXKuicr/bB+3zFtOy+bNWDQzi54dWocdyTkvSs41RdtLDjBpXjZmxtMzsuiblhJ2JOcA8NNrnGtidpQe4uZ5yzhwpJxFM7MY1LVt2JGcO85HSlEkpUuaL+n5sLM4V9d27jvMpHnL2LX/KI9Py2Roz/ZhR3LuBHEvSpKSJL0n6ZVq1t8paa2kdZK+fZrvtUBSkaS1UcvHSdokKU/SPSfrw8zyzWz66eRwLhHtPnCEyfOXU7j7IAtuG82IPh3CjuTc59THSOlOYENVKyQNB2YCmcC5wHhJg6LadJXULmpZdTOMLQTGRbVNAh4GrgSGAjdJGhqsO1vSK1E/XWP9gM4lur2HjnLrYyvYXLSPR6dkkDmgU9iRnKtSXIuSpN7A1cC8apqcBWSb2QEzKwP+AlwT1eZi4PeSWgZ9zgR+XVVnZvYOUBK1OBPIC0ZAR4BngYlB+zVmNj7qp6gWn2uCpLmlpaU1NXUudAePlDN9YQ7rCkt5eNIoLhrcJexIzlUr3iOlXwDfBSqqWb8WuEhSmqQU4CqgT+UGZrYEeANYLGkSMA24LoYMvYDtlZ4XBMuqFGSZA4yUdG9VbczsZTOblZqaGkMM5+rf4bJyZj2ZQ862En5+wwguH9ot7EjOnVTczr6TNB4oMrNcSZdU1cbMNkj6CfAmsB9YBZRX0e5BSc8CjwADzWxfvHKbWTEwO179O1dfjpZX8I2n3+OvH+7kwWvPYcK5PcOO5FyN4jlSugD4iqStRHaZXSbpqehGZjbfzM4zsy8Au4APottIuggYDrwI3B9jjkJOHH31DpY512iVVxh3LV7FnzZ8yg8nDuP6jD41v8i5BBC3omRm95pZbzPrD9wI/NnMbolud+zEAkl9iRxPeiZq/UhgLpHjQFOBNEkPxBBlBTBY0gBJLYIsL53CR3Iu4ZVXGGsLS/nOc6t45f1PuOfKM5kytn/YsZyrtVAunpX0GjDDzD4GficpDTgKfMPMdkc1TwGuN7PNwWunALdV0+8i4BKgs6QC4H4zmy/pDiLHpZKABWa2ru4/lXP1r6LC2LhjL0vzi1m6uZjlW4rZc6gMgLu+dAazLx4YckLnYiMzCztDg5WRkWE5OTlhx3BNiJnxYdE+lm6OFKHsLcXsOnAUgL6dUhibnsbYgWlkpafRPdVvruoSk6RcM8uoap3fZsi5BGZm5O/cHylC+cVk5xezc98RAHp1aM1lZ3Zj7MBIIerlN1R1jYAXJecSiJnxUcmB40VoWX4xn+45DEC39i25cFDnSBFK70yfTq2RFHJi5+qWFyXnQlawq1IR2lzMx6WHAOjctiVZ6Z2CIpTGgM5tvAi5Rs+LknP1bEfpIZbm7zxeiLaXHASgY0oyWelpzL4kUoQGdW3rRcg1OV6UnIuzz/YePn523LL8Yrbs3A9A+1bNGZOextTzBzB2YBpDurWjWTMvQq5p86LkXB0r2X+EZUERWppfTF5R5AYkbVs2J3NAJ27O7MvYgWmc1aM9SV6EnDuBFyXnTlPpgaMs2/KPkdDGHXsBSGmRREb/TnxtVG/GDkxjeM/2NE/yKcycOxkvSs7FaM+ho6zYUnJ8JLT+kz2YQavkZmT068TdV/Rg7MA0zundgWQvQs7FxIuSczXYf7iMFVtLjp8dt6awlAqDFknNGNWvA9/+4hmMHZjGuX1Sadk8Key4zjVoXpSci3LwSDm523YdP0Pu/YJSyiqM5CQxok8H7rh0EFkD0xjVtyOtkr0IOVeXvCi5Ju/Q0XLe+2j38ZHQqu27OVJeQVIzcU7vVGZ9IZ2xA9M4r19HUlr4Pxnn4sn/hbkm50hZBasLdh+/f1zuR7s4UlZBM8HwXqlMvaA/WQPTGN2/E21b+j8R5+qT/4tzjV5ZeQXvF5YePzsuZ+suDh4tR4KzurdnclY/xqanMXpAJ1JbJ4cd17kmzYuSa3TKK4x1H5cePztuxZYS9h+JTGg8pFs7bhjdh6z0NLLSO9EhpUXIaZ1zlXlRcg1eRYWxYcee4yOh7C0l7A3mFBrYpQ3/NKoXY9M7Mya9E53btgw5rXPuZLwouQbHzPjg030s3bwzMp3DlhJ2B3MK9U9LYfw5PchKj9w/rmt7n1PIuYbEi5JLeGbG5s/2Hz87bll+McX7I3MK9e7YmsvP+secQj1SfU4h5xoyL0ou4ZgZ24oPHL+J6dL8Yj7bG5lTqEdqKy4+owtZwXQOfTqlhJzWOVeXvChFkZQO/BuQambXhp2nqdhecuD4SGhpfjGfBHMKdWnX8vgU32PT0+iXluLTOTjXiMW9KElKAnKAQjMbX8X6u4AZgAFrgKlmdugU3mcBMB4oMrPhUevGAb8EkoB5ZvZf1fVjZvnAdEnPx5rB1d4npQePXye0NL+Ygl2ROYXS2rSInBkXFKGBXXxiO+eakvoYKd0JbADaR6+Q1Av4FjDUzA5Keg64EVhYqU1X4KCZ7a20bJCZ5UV1txB4CHgi6j2SgIeBy4ECYIWkl4gUqB9H9THNzIpO4TO6GhTtOXR8eu+lm4vZWnwAgA4pyYwZ0IkZFw5g7MDOnNHNJ7ZzrimLa1GS1Bu4GvgP4DsnydBa0lEgBfg4av3FwGxJV5nZYUkzgWuAKys3MrN3JPWvov9MIC8YASHpWWCimf2YyMjqVD7XBGDCoEGDTuXlTcLOfYfJzi85fv+4zZ9FJrZr16o5YwZ04pasfpE5hbq394ntnHPHxXuk9Avgu0C7qlaaWaGknwIfAQeBN83szag2SyQNABZLWgJMIzLqqa1ewPZKzwuAMdU1lpRGpIiOlHRvULyic78MvJyRkTEzhhyN2u4DR1iWX3L8NO0PPo1MbNemRRKjB3Ti+ow+jB2YxrCeqT6xnXOuWnErSpKOHd/JlXRJNW06AhOBAcBuYImkW8zsqcrtzOzBYITzCDDQzPbFK7eZFQOz49V/Y1F68CjLK80ptHFHZE6h1slJZPTvyMQRvRg7MI2ze6X6nELOuVqL50jpAuArkq4CWgHtJT1lZrdUavMlYIuZfQYg6QXgfOCEoiTpImA48CJwP3BHDDkKgT6VnvcOlrkY7DtcFpnYLjgmtO7jYE6h5s04r29H7vpSMKdQ7w60aO5FyDl3auJWlMzsXuBegGCkdHdUQYLIbrssSSlEdt99kciZesdJGgnMJXL8ZwvwtKQHzOy+WkZZAQwOdgEWEjmR4uZT+UxNyYEjZeRs3XW8CK0pLKU8mFNoZJ+O3HHZYM4fmMaIPh18TiHnXJ0J5TolSa8BM8wsOzj1eiVQBrxHpABVlgJcb2abg9dOAW6ros9FwCVAZ0kFwP1mNt/MyiTdAbxB5Iy7BWa2Lj6frOE6dLScldv+UYRWF+zmaLnRvJk4t08Hvn7xQMYGE9u1buFFyDkXHzKzsDM0WBkZGZaTk1NzwwR0uKycVcHEdks3F/Pe9t3H5xQ6u3eH4xesZvTrSBufU8g5V4ck5ZpZRlXr/K9NE3G0vIL3j01sl19M7rZdHDpagQTDerbn1rGRU7RH9+9Eu1Y+p5BzLhxelBqpsvIK1n6853gRytlawoFgTqEzu7fjpsy+jE1PY8yANFJTvAg55xKDF6VGorzC2PDJnhMmttt7ODKn0OCubbn2vN6RIpSeRqc2PrGdcy4xeVFqoCoqjE2f7j1ehJZvKaH0YGROofTObZgwoidj09PISk+jSzuf2M451zB4UWogzIy8on3HT0zI3lJCSTCnUN9OKYwb1p2xAyNFqHuqT2znnGuYvCglKDNjy879x4vQsvwSdu6LzCnUq0NrLh3S9fjEdr06+MR2zrnGwYtSgjAztpccPH4D06X5xXy6J1KEurVvyYWDjs0p1Jk+nVr7nbSdc42SF6UQFe7+x5xCy/KLKdwdmVOoc9vInELHJrYb0NnnFHLONQ1elEKwfEsJdy9ZzUclkTmFOqYkk5Wexu0XpzM2PY1BXX1OIedc0+RFKQTd27diSPd23HZ+f8YOTGNIt3Y+p5BzzuFFKRR901J4dEqVd9hwzrkmzecYcM45lzC8KDnnnEsYXpScc84lDC9KzjnnEoYXJeeccwnDi5JzzrmE4UXJOedcwvCi5JxzLmHIzMLO0GBJ+gzYdoov7wzsrMM4dSlRs3mu2Hiu2Hiu2JxOrn5m1qWqFV6UQiIpx8wS8rYOiZrNc8XGc8XGc8UmXrl8951zzrmE4UXJOedcwvCiFJ65YQc4iUTN5rli47li47liE5dcfkzJOedcwvCRknPOuYThRck551zC8KIUB5IWSCqStLaa9ZL0K0l5kt6XNKrSulslfRj83FqPmSYFWdZI+rukcyut2xosXyUpp64yxZDtEkmlwfuvkvT9SuvGSdoUfJf31HOu/1Mp01pJ5ZI6Bevi8p1J6iPpbUnrJa2TdGcVbcLYvmqTq963sVrmqvftq5a56n37CvpuJWm5pNVBth9U0aalpMXB95ItqX+ldfcGyzdJ+nLMAczMf+r4B/gCMApYW836q4A/AgKygOxgeScgP/jdMXjcsZ4ynX/svYArj2UKnm8FOof4fV0CvFLF8iRgM5AOtABWA0PrK1dU2wnAn+P9nQE9gFHB43bAB9GfOaTtqza56n0bq2Wuet++apMrjO0r6FtA2+BxMpANZEW1+WdgTvD4RmBx8Hho8D21BAYE319SLO/vI6U4MLN3gJKTNJkIPGERy4AOknoAXwbeMrMSM9sFvAWMq49MZvb34D0BlgG96+J9a6MW31d1MoE8M8s3syPAs0S+2zBy3QQsqqv3ro6ZfWJmK4PHe4ENQK+oZmFsXzXmCmMbq+X3VZ24bV+nkKtetq8gj5nZvuBpcvATfUbcRODx4PHzwBclKVj+rJkdNrMtQB6R77HWvCiFoxewvdLzgmBZdcvr23Qi/6d9jAFvSsqVNCuEPABjg90Jf5Q0LFiWEN+XpBQif9x/V2lx3L+zYJfJSCL/J1tZqNvXSXJVVu/bWA25Qtu+avq+wti+JCVJWgUUEfkfmWq3MTMrA0qBNOrgO2t+ipldIyXpUiJ/MC6stPhCMyuU1BV4S9LGYBRRX1YSuVfWPklXAb8HBtfj+9dkAvA3M6s8qorrdyapLZE/Ut82sz111e/pqk2uMLaxGnKFtn3V8r9jvW9fZlYOjJDUAXhR0nAzq/LYal3zkVI4CoE+lZ73DpZVt7xeSDoHmAdMNLPiY8vNrDD4XQS8SIzD8dNlZnuO7U4ws9eAZEmdCfn7quRGonatxPM7k5RM5A/Z02b2QhVNQtm+apErlG2splxhbV+1+b4C9bp9Rb3PbuBtPr+b9/h3I6k5kAoUUxffWTwOlPmPAfSn+gP3V3PigejlwfJOwBYiB6E7Bo871VOmvkT2/54ftbwN0K7S478D4+r5++rOPy70zgQ+Cr675kQO1g/gHweih9VXrmB9KpHjTm3q4zsLPvcTwC9O0qbet69a5qr3bayWuep9+6pNrjC2r6DPLkCH4HFr4K/A+Kg23+DEEx2eCx4P48QTHfKJ8UQH330XB5IWETmjp7OkAuB+IgcLMbM5wGtEzpDKAw4AU4N1JZJ+BKwIuvqhnThkj2em7xPZJ/ybyPFKyixyB+BuRIbvEPlH+oyZvV4XmWLIdi3wdUllwEHgRov8CyiTdAfwBpEzpRaY2bp6zAXwT8CbZra/0kvj+Z1dAEwG1gT7/AG+R+QPfmjbVy1zhbGN1SZXGNtXbXJB/W9fEDkz8HFJSUT2pj1nZq9I+iGQY2YvAfOBJyXlESmaNwa510l6DlgPlAHfsMiuwFrz2ww555xLGH5MyTnnXMLwouSccy5heFFyzjmXMLwoOeecSxhelJxzziUMPyXcuQQjqRxYQ+T08zIi17P83MwqQg3mXD3wouRc4jloZiMAgtvIPAO0J3Kd1GmRlBTrdSPO1SfffedcArPIbWRmAXcoIknSf0taocjcRLcDSGom6TeSNkp6S9Jrkq4N1m2V9BNJK4HrJF0haamklZKWBPdfQ9J5kv4S3OTzjeDO4s7VKy9KziU4M8snckeBrkRuZFpqZqOB0cBMSQOAa4jcEmkokTsFjI3qptjMRgF/Au4DvhQ8zwG+E9yH7dfAtWZ2HrAA+I94fzbnovnuO+caliuAc46NgojcG20wkTtuLwmOO+2Q9HbU6xYHv7OIFK6/BbepaQEsBYYAw4nccRoiRfCTOH4O56rkRcm5BCcpHSgnMreNgG+a2RtRba6qoZtj904Tkflxbop6/dnAOjOLHmE5V698951zCUxSF2AO8FBwk9A3iNw8NDlYf4akNsDfgK8Fx5a6EbmRbFWWARdIGhS8vo2kM4BNQBdJY4PlyZUmu3Ou3vhIybnE0zq4c/SxU8KfBH4WrJtH5NjRSkX2s30GfJXIvDxfJHJ35u1EJq4rje7YzD6TdBuwSFLLYPF9ZvZBsEvwV5JSifxt+AVQZ3ddd642/C7hzjUSktpaZPbUNGA5cIGZ7Qg7l3Ox8JGSc43HK8H01S2AH3lBcg2Rj5Scc84lDD/RwTnnXMLwouSccy5heFFyzjmXMLwoOeecSxhelJxzziWM/w/hWRvqRy6e1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import gc\n",
    "rmses = []\n",
    "degrees = [1, 2, 3]\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    poly_reg = linear_model.LogisticRegression(penalty='l2', C = 0.01)\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    print(\"Fit Deg: \", deg)\n",
    "    predict_train = poly_reg.predict(x_poly_train)\n",
    "    predict_test = poly_reg.predict(x_poly_test)\n",
    "    print(\"Predict Deg: \", deg)\n",
    "    poly_mse = mean_squared_error(y_test, predict_test)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    \n",
    "    print(\"Training Set Results\")\n",
    "    print(confusion_matrix(y_train,predict_train))\n",
    "    print(classification_report(y_train,predict_train))\n",
    "    print(confusion_matrix(y_test,predict_test))\n",
    "    print(classification_report(y_test,predict_test))\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "    \n",
    "    del poly_features\n",
    "    del x_poly_train\n",
    "    del poly_reg\n",
    "    del x_poly_test\n",
    "    del predict_test\n",
    "    del predict_train\n",
    "    gc.collect()\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb0ded-2cff-4252-a196-839ab7a9f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# # create transform\n",
    "# trans = PolynomialFeatures(degree=min_deg)\n",
    "# # fit and transform\n",
    "# X = trans.fit_transform(X)\n",
    "# print('Degree: %d, Features: %d' % (min_deg, X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0432f-db23-4621-9bac-0e74fccc938a",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
