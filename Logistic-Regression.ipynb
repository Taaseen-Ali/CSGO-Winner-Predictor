{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df10e46-3ecd-43b1-9465-28c3591509a8",
   "metadata": {},
   "source": [
    "# CSGO Match Prediction with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c3766f-a685-4de8-9e54-55260aeb09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65df54f6-f145-43e3-92e0-9ccc01c2b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas to try\n",
    "# ============\n",
    "# - higher learning rate, higher c, with one hot encoding\n",
    "# - polyfit with no one-hot\n",
    "# - polyfit with one hot\n",
    "# - psuedo one-hot encoding vs summing winner data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355d01f-cd67-45d7-8e1b-bc834e266529",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3066d4-c078-4497-a50c-f2f5e1f25e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33cd1b4-a7ac-40cb-b939-404d905ef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4426f355-9936-459c-9893-a05a88c3e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = []\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d69670e7-7527-465b-bb96-33d755fcd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bb54f4-501e-40ff-88bc-c80b07aec1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b596710a-c30b-4819-ba79-52b0d9f898e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c8a893-3b5f-41b2-82ce-c9a0d591c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/34/wwdjpw3x60scvghx_lqvyv440000gp/T/ipykernel_87754/2170638273.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "/var/folders/34/wwdjpw3x60scvghx_lqvyv440000gp/T/ipykernel_87754/2170638273.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>_map</th>\n",
       "      <th>1_t1</th>\n",
       "      <th>2_t1</th>\n",
       "      <th>3_t1</th>\n",
       "      <th>4_t1</th>\n",
       "      <th>5_t1</th>\n",
       "      <th>6_t1</th>\n",
       "      <th>7_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>7_winner</th>\n",
       "      <th>8_winner</th>\n",
       "      <th>9_winner</th>\n",
       "      <th>10_winner</th>\n",
       "      <th>11_winner</th>\n",
       "      <th>12_winner</th>\n",
       "      <th>13_winner</th>\n",
       "      <th>14_winner</th>\n",
       "      <th>15_winner</th>\n",
       "      <th>t1_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1088</td>\n",
       "      <td>1648</td>\n",
       "      <td>0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1088</td>\n",
       "      <td>1648</td>\n",
       "      <td>1</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>28500.0</td>\n",
       "      <td>31900.0</td>\n",
       "      <td>31700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1088</td>\n",
       "      <td>1648</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>23150.0</td>\n",
       "      <td>21850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1648</td>\n",
       "      <td>2049</td>\n",
       "      <td>1</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>18050.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>25850.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>27250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1648</td>\n",
       "      <td>2049</td>\n",
       "      <td>0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24500.0</td>\n",
       "      <td>27550.0</td>\n",
       "      <td>29350.0</td>\n",
       "      <td>31950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43229</th>\n",
       "      <td>768</td>\n",
       "      <td>1401</td>\n",
       "      <td>9</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>26750.0</td>\n",
       "      <td>27450.0</td>\n",
       "      <td>26950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43230</th>\n",
       "      <td>2049</td>\n",
       "      <td>1741</td>\n",
       "      <td>4</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>17400.0</td>\n",
       "      <td>22050.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>25650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43231</th>\n",
       "      <td>2039</td>\n",
       "      <td>1636</td>\n",
       "      <td>2</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>29150.0</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43232</th>\n",
       "      <td>625</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>22950.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>26850.0</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43233</th>\n",
       "      <td>23</td>\n",
       "      <td>895</td>\n",
       "      <td>8</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43234 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_1  team_2  _map    1_t1     2_t1     3_t1     4_t1     5_t1  \\\n",
       "0        1088    1648     0  4350.0   1100.0  22100.0   9350.0  25750.0   \n",
       "1        1088    1648     1  3900.0   7400.0  23250.0  28500.0  31900.0   \n",
       "2        1088    1648     2  4150.0  14300.0   2000.0  24800.0   9000.0   \n",
       "3        1648    2049     1  4150.0  18050.0  21000.0  25850.0  25000.0   \n",
       "4        1648    2049     0  4200.0  10000.0  22000.0  24500.0  27550.0   \n",
       "...       ...     ...   ...     ...      ...      ...      ...      ...   \n",
       "43229     768    1401     9  4250.0   7400.0  17200.0  18500.0  26750.0   \n",
       "43230    2049    1741     4  4250.0   1600.0  24250.0  17400.0  22050.0   \n",
       "43231    2039    1636     2  4350.0   7650.0  20000.0  21500.0  29150.0   \n",
       "43232     625     313     2  4150.0  11800.0   1200.0  22950.0  25750.0   \n",
       "43233      23     895     8  4100.0  17700.0  18950.0  13200.0  24000.0   \n",
       "\n",
       "          6_t1     7_t1  ...  7_winner  8_winner  9_winner  10_winner  \\\n",
       "0      10400.0  24600.0  ...       2.0       2.0       1.0        2.0   \n",
       "1      31700.0  18950.0  ...       2.0       1.0       1.0        2.0   \n",
       "2      23150.0  21850.0  ...       1.0       2.0       2.0        2.0   \n",
       "3      25000.0  27250.0  ...       1.0       1.0       1.0        1.0   \n",
       "4      29350.0  31950.0  ...       2.0       1.0       1.0        1.0   \n",
       "...        ...      ...  ...       ...       ...       ...        ...   \n",
       "43229  27450.0  26950.0  ...       2.0       1.0       2.0        2.0   \n",
       "43230   6600.0  25650.0  ...       1.0       1.0       1.0        1.0   \n",
       "43231  26900.0   8750.0  ...       2.0       2.0       2.0        1.0   \n",
       "43232  26850.0  27850.0  ...       1.0       1.0       2.0        1.0   \n",
       "43233  20550.0  14500.0  ...       1.0       1.0       1.0        2.0   \n",
       "\n",
       "       11_winner  12_winner  13_winner  14_winner  15_winner  t1_t  \n",
       "0            2.0        2.0        2.0        2.0        2.0     1  \n",
       "1            2.0        2.0        2.0        2.0        2.0     0  \n",
       "2            2.0        2.0        2.0        2.0        2.0     1  \n",
       "3            1.0        1.0        1.0        1.0        1.0     1  \n",
       "4            1.0        1.0        1.0        1.0        1.0     0  \n",
       "...          ...        ...        ...        ...        ...   ...  \n",
       "43229        2.0        2.0        2.0        2.0        2.0     1  \n",
       "43230        1.0        1.0        2.0        2.0        2.0     1  \n",
       "43231        1.0        2.0        2.0        1.0        1.0     0  \n",
       "43232        1.0        1.0        1.0        1.0        1.0     1  \n",
       "43233        1.0        1.0        1.0        1.0        1.0     1  \n",
       "\n",
       "[43234 rows x 49 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc479b72-1d69-4df3-9bac-b85a3f3744d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "43229    2.0\n",
       "43230    1.0\n",
       "43231    1.0\n",
       "43232    1.0\n",
       "43233    1.0\n",
       "Name: match_winner, Length: 43234, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1414a-0b65-4319-845e-32b4c2cfaa86",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb8be17-2722-4233-a204-b5c38fb1c1d6",
   "metadata": {},
   "source": [
    "## One-Hot Conversion (Encoding Teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e67491-ae60-46fd-bd5a-976f9f23b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the team names back into strings again\n",
    "num_to_team = dict(zip(range(len(set_of_teams)), set_of_teams))\n",
    "all_teams = [num_to_team[i] for i in range(len(set_of_teams))]\n",
    "\n",
    "# Extract the team data from the original DataFrame\n",
    "team_1_arr = np.array(X[\"team_1\"])\n",
    "team_2_arr = np.array(X[\"team_2\"])\n",
    "\n",
    "# Create the one-hot vectors for each row of the data, one for each team\n",
    "one_hot_t1 = np.zeros((team_1_arr.size, len(num_to_team)))\n",
    "one_hot_t1[np.arange(team_1_arr.size), team_1_arr] = 1\n",
    "\n",
    "one_hot_t2 = np.zeros((team_2_arr.size, len(num_to_team)))\n",
    "one_hot_t2[np.arange(team_2_arr.size), team_2_arr] = 1\n",
    "\n",
    "# Combine the matrix of one-hot vectors for team_1 and team_2 together to create a single matrix\n",
    "one_hot = np.hstack((one_hot_t1, one_hot_t2))\n",
    "\n",
    "# Turn the numpy array into a pandas DataFrame and add it to the dataset\n",
    "one_hot_df = pd.DataFrame(one_hot, columns = [\"team_1_%s\" %(i) for i in all_teams] + [\"team_2_%s\" %(i) for i in all_teams])\n",
    "X = X.drop(columns = [\"team_1\", \"team_2\"])\n",
    "X = X.join(one_hot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59aed415-2eab-4e7e-aed0-e170fd855334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a5eef-ed81-47a7-9c64-9d633d677c5c",
   "metadata": {},
   "source": [
    "## LogReg w/ No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32b784-1f9b-4d3d-8b8b-c593f86a5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_none = linear_model.LogisticRegression(penalty='none') # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014dae8-a990-40ee-8194-cff676aeaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_none.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ac3b4-084e-4cfc-bef1-53ea9f1d019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = logreg_ridge_none.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341d4d7-7885-4aac-a1fa-ed7e3ffd3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_none.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_none.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c219c-bcec-439a-8536-6784f2326e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a3448-5b93-43ea-9ce2-82b90d5d2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_none, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcf236-c624-4cd7-9e6e-8f364706842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b26bf-8f1b-4c77-a5c4-2098bf1e519f",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238f27d-d1c3-4953-87b7-f0816e9838e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l1 = linear_model.LogisticRegression(solver='liblinear', penalty='l1',warm_start=True, C = 0.01) # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d564e0-74fe-43b5-8d02-d8ac2edd6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af83e63-6336-4469-812c-5e34f23adcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_l1 = logreg_ridge_l1.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l1 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84406b-90e7-4af7-a091-2931d5b4a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l1.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l1.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7289d95-1ac7-4d27-813d-6b11f28c0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b3571-64c7-430d-8244-b46b762439cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da29ead-ec78-441e-816c-eb2ae6aab8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l1,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebee315-c6f4-497d-9e04-be0d284225ac",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad92fd-ca5e-40ed-8a06-f1bdabc32ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l2 = linear_model.LogisticRegression(penalty='l2', C = 0.01) # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddd862-b81a-444c-9b19-a44ffcb47051",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e5edf-096b-4ef2-9785-de3a0d51af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_l2 = logreg_ridge_l2.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l2 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a024e-0ae7-4663-974d-7abe2f4507bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l2.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l2.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b2543-26f2-4f57-bf4d-cb0d0af5e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4674da8-cff6-417c-a812-b1f8548b6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l2, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab06ab-c282-4f0d-a763-6d4040591692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l2,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd8a5f-5d37-4bb5-99ba-29caa7c434d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5b07f-17bc-4736-b0cd-2c7afab7d2c6",
   "metadata": {},
   "source": [
    "## Polynomial Transformation Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5fa31-5713-4d9b-ad98-c503025097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful polynomial library\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568dfaf7-851c-4727-9fe9-d55fa758387f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95368a-5c3f-4df5-88b6-79d8055a9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fa4b2-0bca-443c-8348-455db8e901b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1c8e8-f48b-4df9-b1df-56aef0a46955",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = []\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7cdd5-1e31-4e50-9b3c-cdbc1b4b428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8edd54-e052-4026-8f0d-79fb6cc5b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)\n",
    "df = df.sample(frac = .55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d1f32-0106-4ebb-b029-6b371de8506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e78bb-2326-4381-b9db-50faea7a8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8f983-5ed4-4c5b-b8d5-0c4de3b641f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3981e86-6482-478b-bc26-83d6f3a7c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import gc\n",
    "rmses = []\n",
    "degrees = np.arange(2, 10)\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    poly_reg = linear_model.LogisticRegression(penalty='l2', C = 0.01)\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    print(\"Fit Deg: \", deg)\n",
    "    poly_predict = poly_reg.predict(x_poly_test)\n",
    "    print(\"Predict Deg: \", deg)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    \n",
    "    print(\"Training Set Results\")\n",
    "    print(confusion_matrix(y_train,predict_train))\n",
    "    print(classification_report(y_train,predict_train))\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "    \n",
    "    del poly_features\n",
    "    del x_poly_train\n",
    "    del poly_reg\n",
    "    del x_poly_test\n",
    "    del poly_predict\n",
    "    gc.collect()\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb0ded-2cff-4252-a196-839ab7a9f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# create transform\n",
    "trans = PolynomialFeatures(degree=dval[imin])\n",
    "# fit and transform\n",
    "X = trans.fit_transform(X)\n",
    "print('Degree: %d, Features: %d' % (dval[imin], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0432f-db23-4621-9bac-0e74fccc938a",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
