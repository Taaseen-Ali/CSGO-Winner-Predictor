{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df10e46-3ecd-43b1-9465-28c3591509a8",
   "metadata": {},
   "source": [
    "# CSGO Match Prediction with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c3766f-a685-4de8-9e54-55260aeb09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355d01f-cd67-45d7-8e1b-bc834e266529",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3066d4-c078-4497-a50c-f2f5e1f25e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33cd1b4-a7ac-40cb-b939-404d905ef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index) # Get winner of the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4426f355-9936-459c-9893-a05a88c3e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = [] # Creation of the winners column for the dataset\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69670e7-7527-465b-bb96-33d755fcd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bb54f4-501e-40ff-88bc-c80b07aec1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [ # Rounds we are not parsing, we only care about rounds until halftime\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b596710a-c30b-4819-ba79-52b0d9f898e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c8a893-3b5f-41b2-82ce-c9a0d591c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-072520d650ff>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "<ipython-input-8-072520d650ff>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>_map</th>\n",
       "      <th>1_t1</th>\n",
       "      <th>2_t1</th>\n",
       "      <th>3_t1</th>\n",
       "      <th>4_t1</th>\n",
       "      <th>5_t1</th>\n",
       "      <th>6_t1</th>\n",
       "      <th>7_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>7_winner</th>\n",
       "      <th>8_winner</th>\n",
       "      <th>9_winner</th>\n",
       "      <th>10_winner</th>\n",
       "      <th>11_winner</th>\n",
       "      <th>12_winner</th>\n",
       "      <th>13_winner</th>\n",
       "      <th>14_winner</th>\n",
       "      <th>15_winner</th>\n",
       "      <th>t1_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2603</td>\n",
       "      <td>1494</td>\n",
       "      <td>0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2603</td>\n",
       "      <td>1494</td>\n",
       "      <td>1</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>28500.0</td>\n",
       "      <td>31900.0</td>\n",
       "      <td>31700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2603</td>\n",
       "      <td>1494</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>23150.0</td>\n",
       "      <td>21850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1494</td>\n",
       "      <td>2909</td>\n",
       "      <td>1</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>18050.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>25850.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>27250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1494</td>\n",
       "      <td>2909</td>\n",
       "      <td>0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24500.0</td>\n",
       "      <td>27550.0</td>\n",
       "      <td>29350.0</td>\n",
       "      <td>31950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43229</th>\n",
       "      <td>854</td>\n",
       "      <td>772</td>\n",
       "      <td>9</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>26750.0</td>\n",
       "      <td>27450.0</td>\n",
       "      <td>26950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43230</th>\n",
       "      <td>2909</td>\n",
       "      <td>2867</td>\n",
       "      <td>4</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>17400.0</td>\n",
       "      <td>22050.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>25650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43231</th>\n",
       "      <td>1354</td>\n",
       "      <td>1341</td>\n",
       "      <td>2</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>29150.0</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43232</th>\n",
       "      <td>1105</td>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>22950.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>26850.0</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43233</th>\n",
       "      <td>2425</td>\n",
       "      <td>898</td>\n",
       "      <td>8</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43234 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_1  team_2  _map    1_t1     2_t1     3_t1     4_t1     5_t1  \\\n",
       "0        2603    1494     0  4350.0   1100.0  22100.0   9350.0  25750.0   \n",
       "1        2603    1494     1  3900.0   7400.0  23250.0  28500.0  31900.0   \n",
       "2        2603    1494     2  4150.0  14300.0   2000.0  24800.0   9000.0   \n",
       "3        1494    2909     1  4150.0  18050.0  21000.0  25850.0  25000.0   \n",
       "4        1494    2909     0  4200.0  10000.0  22000.0  24500.0  27550.0   \n",
       "...       ...     ...   ...     ...      ...      ...      ...      ...   \n",
       "43229     854     772     9  4250.0   7400.0  17200.0  18500.0  26750.0   \n",
       "43230    2909    2867     4  4250.0   1600.0  24250.0  17400.0  22050.0   \n",
       "43231    1354    1341     2  4350.0   7650.0  20000.0  21500.0  29150.0   \n",
       "43232    1105    1979     2  4150.0  11800.0   1200.0  22950.0  25750.0   \n",
       "43233    2425     898     8  4100.0  17700.0  18950.0  13200.0  24000.0   \n",
       "\n",
       "          6_t1     7_t1  ...  7_winner  8_winner  9_winner  10_winner  \\\n",
       "0      10400.0  24600.0  ...       2.0       2.0       1.0        2.0   \n",
       "1      31700.0  18950.0  ...       2.0       1.0       1.0        2.0   \n",
       "2      23150.0  21850.0  ...       1.0       2.0       2.0        2.0   \n",
       "3      25000.0  27250.0  ...       1.0       1.0       1.0        1.0   \n",
       "4      29350.0  31950.0  ...       2.0       1.0       1.0        1.0   \n",
       "...        ...      ...  ...       ...       ...       ...        ...   \n",
       "43229  27450.0  26950.0  ...       2.0       1.0       2.0        2.0   \n",
       "43230   6600.0  25650.0  ...       1.0       1.0       1.0        1.0   \n",
       "43231  26900.0   8750.0  ...       2.0       2.0       2.0        1.0   \n",
       "43232  26850.0  27850.0  ...       1.0       1.0       2.0        1.0   \n",
       "43233  20550.0  14500.0  ...       1.0       1.0       1.0        2.0   \n",
       "\n",
       "       11_winner  12_winner  13_winner  14_winner  15_winner  t1_t  \n",
       "0            2.0        2.0        2.0        2.0        2.0     1  \n",
       "1            2.0        2.0        2.0        2.0        2.0     0  \n",
       "2            2.0        2.0        2.0        2.0        2.0     1  \n",
       "3            1.0        1.0        1.0        1.0        1.0     1  \n",
       "4            1.0        1.0        1.0        1.0        1.0     0  \n",
       "...          ...        ...        ...        ...        ...   ...  \n",
       "43229        2.0        2.0        2.0        2.0        2.0     1  \n",
       "43230        1.0        1.0        2.0        2.0        2.0     1  \n",
       "43231        1.0        2.0        2.0        1.0        1.0     0  \n",
       "43232        1.0        1.0        1.0        1.0        1.0     1  \n",
       "43233        1.0        1.0        1.0        1.0        1.0     1  \n",
       "\n",
       "[43234 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc479b72-1d69-4df3-9bac-b85a3f3744d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "43229    2.0\n",
       "43230    1.0\n",
       "43231    1.0\n",
       "43232    1.0\n",
       "43233    1.0\n",
       "Name: match_winner, Length: 43234, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1414a-0b65-4319-845e-32b4c2cfaa86",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb8be17-2722-4233-a204-b5c38fb1c1d6",
   "metadata": {},
   "source": [
    "## One-Hot Conversion (Encoding Teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e67491-ae60-46fd-bd5a-976f9f23b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the team names back into strings again\n",
    "# import gc\n",
    "# num_to_team = dict(zip(range(len(set_of_teams)), set_of_teams))\n",
    "# all_teams = [num_to_team[i] for i in range(len(set_of_teams))]\n",
    "\n",
    "# # Extract the team data from the original DataFrame\n",
    "# team_1_arr = np.array(X[\"team_1\"])\n",
    "# team_2_arr = np.array(X[\"team_2\"])\n",
    "\n",
    "# # Create the one-hot vectors for each row of the data, one for each team\n",
    "# one_hot_t1 = np.zeros((team_1_arr.size, len(num_to_team)))\n",
    "# one_hot_t1[np.arange(team_1_arr.size), team_1_arr] = 1\n",
    "\n",
    "# one_hot_t2 = np.zeros((team_2_arr.size, len(num_to_team)))\n",
    "# one_hot_t2[np.arange(team_2_arr.size), team_2_arr] = 1\n",
    "\n",
    "# # Combine the matrix of one-hot vectors for team_1 and team_2 together to create a single matrix\n",
    "# one_hot = np.hstack((one_hot_t1, one_hot_t2))\n",
    "\n",
    "# # Turn the numpy array into a pandas DataFrame and add it to the dataset\n",
    "# one_hot_df = pd.DataFrame(one_hot, columns = [\"team_1_%s\" %(i) for i in all_teams] + [\"team_2_%s\" %(i) for i in all_teams])\n",
    "# X = X.drop(columns = [\"team_1\", \"team_2\"])\n",
    "# X = X.join(one_hot_df)\n",
    "# # Freeing memory for training and test dataset splits\n",
    "# del team_1_arr\n",
    "# del team_2_arr\n",
    "# del num_to_team\n",
    "# del all_teams \n",
    "# del one_hot_t1\n",
    "# del one_hot_t2\n",
    "# del one_hot\n",
    "# del one_hot_df\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bf600-5b52-4c54-84c7-b2aa15ed8cff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59aed415-2eab-4e7e-aed0-e170fd855334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a5eef-ed81-47a7-9c64-9d633d677c5c",
   "metadata": {},
   "source": [
    "## LogReg w/ No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c32b784-1f9b-4d3d-8b8b-c593f86a5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_none = linear_model.LogisticRegression(penalty='none') # No regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2014dae8-a990-40ee-8194-cff676aeaa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_none.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13ac3b4-084e-4cfc-bef1-53ea9f1d019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.775019\n",
      "Accuracy on test data = 0.776205\n"
     ]
    }
   ],
   "source": [
    "yhat_train = logreg_ridge_none.predict(X_train)\n",
    "yhat = logreg_ridge_none.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat == y_test)\n",
    "acc_train = np.mean(yhat_train == y_train)\n",
    "print(\"Accuracy on training data = %f\" % acc_train)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f341d4d7-7885-4aac-a1fa-ed7e3ffd3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 1.0\n",
      "Accuracy on the test data is 0.776205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>-0.007230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>-0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>-0.008837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.029567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.051332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>-0.030035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.047878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>0.005810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.018703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>-0.004027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>0.003210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>-0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.013060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.020552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.061834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.015110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.025446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>-0.015186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.034156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.023627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>-0.005831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.008087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>-0.011609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>-0.016917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.012198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>-0.005065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.012370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>-0.028125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.023957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.017590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.229660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.265476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.215251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.273212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.317319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.272643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.296849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.296879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.284550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.272356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.289729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.290814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.267095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.264362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.290205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.122149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1 -0.007230\n",
       "1      team_2 -0.002731\n",
       "2        _map -0.008837\n",
       "3    t1_start  0.029567\n",
       "4        1_t1 -0.051332\n",
       "5        2_t1 -0.030035\n",
       "6        3_t1 -0.047878\n",
       "7        4_t1  0.005810\n",
       "8        5_t1  0.002624\n",
       "9        6_t1  0.021622\n",
       "10       7_t1 -0.018703\n",
       "11       8_t1 -0.004027\n",
       "12       9_t1  0.004775\n",
       "13      10_t1  0.003210\n",
       "14      11_t1 -0.000390\n",
       "15      12_t1 -0.013060\n",
       "16      13_t1 -0.020552\n",
       "17      14_t1 -0.061834\n",
       "18      15_t1  0.015110\n",
       "19       1_t2  0.025446\n",
       "20       2_t2 -0.015186\n",
       "21       3_t2  0.034156\n",
       "22       4_t2  0.023627\n",
       "23       5_t2 -0.005831\n",
       "24       6_t2  0.008087\n",
       "25       7_t2 -0.011609\n",
       "26       8_t2 -0.016917\n",
       "27       9_t2  0.012198\n",
       "28      10_t2 -0.005065\n",
       "29      11_t2  0.012370\n",
       "30      12_t2 -0.028125\n",
       "31      13_t2  0.023957\n",
       "32      14_t2  0.017590\n",
       "33      15_t2  0.229660\n",
       "34   1_winner  0.265476\n",
       "35   2_winner  0.215251\n",
       "36   3_winner  0.273212\n",
       "37   4_winner  0.317319\n",
       "38   5_winner  0.272643\n",
       "39   6_winner  0.296849\n",
       "40   7_winner  0.296879\n",
       "41   8_winner  0.284550\n",
       "42   9_winner  0.272356\n",
       "43  10_winner  0.289729\n",
       "44  11_winner  0.290814\n",
       "45  12_winner  0.267095\n",
       "46  13_winner  0.264362\n",
       "47  14_winner  0.290205\n",
       "48  15_winner -0.122149"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_none.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_none.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48c219c-bcec-439a-8536-6784f2326e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4596, 1223],\n",
       "       [1196, 3794]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "463a3448-5b93-43ea-9ce2-82b90d5d2f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749 (0.007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_none, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31dcf236-c624-4cd7-9e6e-8f364706842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7898264306581887\n",
      "recal:  0.7935082872928176\n",
      "fscore:  0.79166307811558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b26bf-8f1b-4c77-a5c4-2098bf1e519f",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4238f27d-d1c3-4953-87b7-f0816e9838e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l1 = linear_model.LogisticRegression(solver='liblinear', penalty='l1',warm_start=True, C = 0.001) # L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28d564e0-74fe-43b5-8d02-d8ac2edd6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='l1', solver='liblinear', warm_start=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5af83e63-6336-4469-812c-5e34f23adcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.776945\n"
     ]
    }
   ],
   "source": [
    "yhat_l1 = logreg_ridge_l1.predict(X_test) # the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l1 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f84406b-90e7-4af7-a091-2931d5b4a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 0.001\n",
      "Accuracy on the test data is 0.776945\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.034762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.090041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.228992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.176081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.152547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.212317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.157774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.188308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.181963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.179861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.169141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.186318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.181074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.175102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.163254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.133873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1  0.000000\n",
       "1      team_2  0.000000\n",
       "2        _map  0.000000\n",
       "3    t1_start  0.000000\n",
       "4        1_t1  0.000000\n",
       "5        2_t1  0.000000\n",
       "6        3_t1  0.000000\n",
       "7        4_t1  0.000000\n",
       "8        5_t1  0.000000\n",
       "9        6_t1  0.000000\n",
       "10       7_t1  0.000000\n",
       "11       8_t1  0.000000\n",
       "12       9_t1  0.000000\n",
       "13      10_t1  0.000000\n",
       "14      11_t1  0.000000\n",
       "15      12_t1  0.000000\n",
       "16      13_t1  0.000000\n",
       "17      14_t1 -0.034762\n",
       "18      15_t1  0.000000\n",
       "19       1_t2  0.000000\n",
       "20       2_t2  0.000000\n",
       "21       3_t2  0.000000\n",
       "22       4_t2  0.000000\n",
       "23       5_t2  0.000000\n",
       "24       6_t2  0.000000\n",
       "25       7_t2  0.000000\n",
       "26       8_t2  0.000000\n",
       "27       9_t2  0.000000\n",
       "28      10_t2  0.000000\n",
       "29      11_t2  0.000000\n",
       "30      12_t2  0.000000\n",
       "31      13_t2  0.000000\n",
       "32      14_t2  0.000000\n",
       "33      15_t2  0.090041\n",
       "34   1_winner  0.228992\n",
       "35   2_winner  0.176081\n",
       "36   3_winner  0.152547\n",
       "37   4_winner  0.212317\n",
       "38   5_winner  0.157774\n",
       "39   6_winner  0.188308\n",
       "40   7_winner  0.181963\n",
       "41   8_winner  0.179861\n",
       "42   9_winner  0.169141\n",
       "43  10_winner  0.186318\n",
       "44  11_winner  0.181074\n",
       "45  12_winner  0.175102\n",
       "46  13_winner  0.163254\n",
       "47  14_winner  0.133873\n",
       "48  15_winner  0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l1.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l1.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7289d95-1ac7-4d27-813d-6b11f28c0d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4513, 1132],\n",
       "       [1279, 3885]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65b3571-64c7-430d-8244-b46b762439cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.753 (0.008)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5da29ead-ec78-441e-816c-eb2ae6aab8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7994685562444641\n",
      "recal:  0.7791781767955801\n",
      "fscore:  0.789192970184489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l1,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebee315-c6f4-497d-9e04-be0d284225ac",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dad92fd-ca5e-40ed-8a06-f1bdabc32ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l2 = linear_model.LogisticRegression(penalty='l2', C = 0.001) # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4ddd862-b81a-444c-9b19-a44ffcb47051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a11e5edf-096b-4ef2-9785-de3a0d51af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.774725\n"
     ]
    }
   ],
   "source": [
    "yhat_l2 = logreg_ridge_l2.predict(X_test) # the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l2 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a63a024e-0ae7-4663-974d-7abe2f4507bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 0.001\n",
      "Accuracy on the test data is 0.774725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>-0.007650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>-0.002190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>-0.005426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.026797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.097085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>-0.071391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.061722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>-0.035050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>-0.042636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>-0.025149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.053498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>-0.044649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>-0.035780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>-0.036432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>-0.043293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.052116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.052510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.082201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.008088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.091569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>0.045883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.056435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.056596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>0.037125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.045323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>0.030140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>0.028939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.046776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>0.034506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.051105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>0.020463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.057047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.049755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.128030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.157608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.154163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.187386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.208586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.179342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.198478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.195013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.189644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.182213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.194589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.196764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.186225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.193178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.235343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.179023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1 -0.007650\n",
       "1      team_2 -0.002190\n",
       "2        _map -0.005426\n",
       "3    t1_start  0.026797\n",
       "4        1_t1 -0.097085\n",
       "5        2_t1 -0.071391\n",
       "6        3_t1 -0.061722\n",
       "7        4_t1 -0.035050\n",
       "8        5_t1 -0.042636\n",
       "9        6_t1 -0.025149\n",
       "10       7_t1 -0.053498\n",
       "11       8_t1 -0.044649\n",
       "12       9_t1 -0.035780\n",
       "13      10_t1 -0.036432\n",
       "14      11_t1 -0.043293\n",
       "15      12_t1 -0.052116\n",
       "16      13_t1 -0.052510\n",
       "17      14_t1 -0.082201\n",
       "18      15_t1  0.008088\n",
       "19       1_t2  0.091569\n",
       "20       2_t2  0.045883\n",
       "21       3_t2  0.056435\n",
       "22       4_t2  0.056596\n",
       "23       5_t2  0.037125\n",
       "24       6_t2  0.045323\n",
       "25       7_t2  0.030140\n",
       "26       8_t2  0.028939\n",
       "27       9_t2  0.046776\n",
       "28      10_t2  0.034506\n",
       "29      11_t2  0.051105\n",
       "30      12_t2  0.020463\n",
       "31      13_t2  0.057047\n",
       "32      14_t2  0.049755\n",
       "33      15_t2  0.128030\n",
       "34   1_winner  0.157608\n",
       "35   2_winner  0.154163\n",
       "36   3_winner  0.187386\n",
       "37   4_winner  0.208586\n",
       "38   5_winner  0.179342\n",
       "39   6_winner  0.198478\n",
       "40   7_winner  0.195013\n",
       "41   8_winner  0.189644\n",
       "42   9_winner  0.182213\n",
       "43  10_winner  0.194589\n",
       "44  11_winner  0.196764\n",
       "45  12_winner  0.186225\n",
       "46  13_winner  0.193178\n",
       "47  14_winner  0.235343\n",
       "48  15_winner -0.179023"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l2.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l2.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "035b2543-26f2-4f57-bf4d-cb0d0af5e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4646, 1289],\n",
       "       [1146, 3728]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4674da8-cff6-417c-a812-b1f8548b6075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750 (0.007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l2, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ab06ab-c282-4f0d-a763-6d4040591692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7828138163437237\n",
      "recal:  0.8021408839779005\n",
      "fscore:  0.7923595122367186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l2,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd8a5f-5d37-4bb5-99ba-29caa7c434d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5b07f-17bc-4736-b0cd-2c7afab7d2c6",
   "metadata": {},
   "source": [
    "## Polynomial Transformation Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d5fa31-5713-4d9b-ad98-c503025097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful polynomial library\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568dfaf7-851c-4727-9fe9-d55fa758387f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae95368a-5c3f-4df5-88b6-79d8055a9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a4fa4b2-0bca-443c-8348-455db8e901b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fe1c8e8-f48b-4df9-b1df-56aef0a46955",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = []\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caf7cdd5-1e31-4e50-9b3c-cdbc1b4b428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f8edd54-e052-4026-8f0d-79fb6cc5b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)\n",
    "df = df.sample(frac = .55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a7d1f32-0106-4ebb-b029-6b371de8506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "124e78bb-2326-4381-b9db-50faea7a8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-9df4de8fea1f>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "<ipython-input-41-9df4de8fea1f>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18c8f983-5ed4-4c5b-b8d5-0c4de3b641f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3981e86-6482-478b-bc26-83d6f3a7c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Deg:  1\n",
      "Predict Deg:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\justin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Deg:  2\n",
      "Predict Deg:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\justin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Deg:  3\n",
      "Predict Deg:  3\n",
      "Best degree 1 with RMSE 0.4738759885044573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEGCAYAAADFWoruAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAq/ElEQVR4nO3deXxV9Z3/8ddbxAVFVCSpApZVBHFBI+K+ABYVS2vVAXdFqW1ttZ22o62/Om3ttGNnujs6qNRaF1xaO25VAR0dW0FAQYQAAi6AmrCGfUny+f1xTmi4JiSB3Nyb5P18PO6De8/53u/53OuBt99zzv0eRQRmZmb5YLdcF2BmZlbFoWRmZnnDoWRmZnnDoWRmZnnDoWRmZnlj91wX0JwddNBB0a1bt1yXYWbWrEyfPn15RHSqaZ1DaRd069aNadOm5boMM7NmRdIHta3z4TszM8sbDiUzM8sbDiUzM8sbDiUzM8sbDiUzM8sbDqUMknpIuk/SE7muxcystclqKEl6X9IsSTMk1XrttKQ2kt6S9Mwubm+cpFJJ72QsHyZpnqQFkm7eUR8RsSgiRu9KHWZmtnOaYqR0ZkQcExFFO2hzI1Bc0wpJBZLaZyzrVUs/9wPDMtq2Ae4EzgH6AaMk9UvXHSnpmYxHQb0+lZlZK3Xv/y1i+gcrs9J3zg/fSeoCnAfcW0uT04G/SNozbX8d8NuaGkbEq0DmNzUQWJCOgLYA44ERaftZETE841Faj5rPlzS2rKysPh/RzKzFuPPlBdz+bDFPTF+Slf6zHUoBvChpuqQxtbT5FfBdoLLGDiIeB14AHpV0KXANcFEDaugMLK72ekm6rEaSOkq6Gxgg6ZZaano6IsZ06NChAWWYmTVvd768gJ+/MI8RxxzCj0f0z8o2sj3N0CkRsTQ9JDZB0tx0NAOApOFAaURMl3RGbZ1ExB2SxgN3AT0jYl22Co6IFcD12erfzKw5+u2kd/nPCfP5wjGH8J8XH0Ob3ZSV7WR1pBQRS9M/S4EnSQ6lVXcy8HlJ75McVjtL0oOZ/Ug6Feif9nFbA8tYCnSt9rpLuszMzOrhN2kgXTCgc1YDCbIYSpL2qbpAQdI+wNnAdlfFRcQtEdElIroBI4GXIuKyjH4GAGNJzgNdDXSUdHsDSpkK9JbUXdIe6Xae2smPZWbWqvx64rv8YsJ8Lji2Mz+/6OisBhJkd6RUCLwmaSbwBvBsRDwPIOk5SYfUs592wMURsTAiKoErgBpnmJX0CPA60EfSEkmjI6IcuIHkvFQx8FhEzN6lT2Zm1gr8auJ8fjlxPl86tgs/vzD7gQSgiMj6RlqqoqKi8K0rzKwl+uWE+fx60rtceFwX/v1LRzVqIEmaXtvPhHJ+SbiZmeWXqkC6KAuBVBff5M/MzACICH458V1+Uy2QdmvCQAKHkpmZkQbShPn85qUFXFzUhZ9d0PSBBA4lM7NWLyL4xYT5/PalBfxTUVd+esGROQkkcCiZmbVqEcF/vjif3728gJHHd+Xfvpi7QAKHkplZqxUR/MeL87jz5YWMGtiVn3wht4EEDiUzs1YpIvj5C/P4r/9dyKiBh/KTL/TPeSCBQ8nMrNWJCO54YR53/e9CLjnhUG4fkR+BBA4lM7NWJSL42fNz+e9XFnHpCYfy4zwKJHAomZm1GhHBz/46l/9+dRGXDTqUH30+vwIJHEpmZq1CRPDTv85l7KuLuHzQZ/nRiCOQ8iuQwKFkZtbiRQT/9lwx9/zfe1xx4mf54efzM5DAoWRm1qJFBD95tph7X3uPK0/8LP+ax4EEDiUzsxYrIrj92WLue+09rjqpG7ed3y+vAwkcSmZmLVJE8ONnihn3t+YTSOBQMjNrcSKCHz0zh9//7X2uPrkbPxjePAIJHEpmZi1K9UC65uTu/L/hfZtNIIFDycysxYgIfvj0HO7/+/uMPqU7t57XvAIJfOfZT5HUQ9J9kp7IdS1mZvVVPZCubaaBBFkOJUnvS5olaYakaTWs30vSG5JmSpot6Ye7uL1xkkolvZOxfJikeZIWSLp5R31ExKKIGL0rdZiZNaWI4LanZnP/39/nulO78/1mGkjQNCOlMyPimIgoqmHdZuCsiDgaOAYYJmlQ9QaSCiS1z1jWq5Zt3Q8My2jbBrgTOAfoB4yS1C9dd6SkZzIeBQ3/iGZmuRER/OB/ZvPA6x8w5rQefO/c5htIkONzShERwLr0Zdv0ERnNTgeul3RuRGyWdB1wAUnIZPb3qqRuGYsHAgsiYhGApPHACGBORMwChjfW5zEza0qVlcEPnnqHByd/yJdP68HN5xzerAMJsj9SCuBFSdMljampgaQ2kmYApcCEiJiyXQcRjwMvAI9KuhS4BrioATV0BhZXe70kXVYjSR0l3Q0MkHRLLW3OlzS2rKysAWWYmTWeysrg//1PEkjXn96zRQQSZD+UTomIY0lGNV+TdFpmg4ioiIhjgC7AQEn9a2hzB7AJuAv4fESsy2zTWCJiRURcHxE9I+KntbR5OiLGdOjQIVtlmJnVqrIyuPV/3uGhKR/ylTN68i/D+rSIQIIsh1JELE3/LAWeJDmUVlvb1cDLZJwTApB0KtA/7eO2BpaxFOha7XWXdJmZWbNTWRl8/y/v8PCUD/nqGT357udaTiBBFkNJ0j5VFyhI2gc4G8i8Kq6TpP3T53sDQ4G5GW0GAGNJzgNdDXSUdHsDSpkK9JbUXdIewEjgqZ36UGZmOZQE0iweeeNDvnZmT77TwgIJsjtSKgRekzQTeAN4NiKeB5D0nKRDgIOBlyW9TRIeEyLimYx+2gEXR8TCiKgErgA+qGmDkh4BXgf6SFoiaXRElAM3kJyXKgYei4jZjf5pzcyyqLIy+N6Ts3jkjcXccGYvvn12ywskACUXwNnOKCoqimnTPvXzKzOzRlUVSOOnLubrZ/XiW0MPa9aBJGl6LT8T8jRDZmb5rLIyuOXPs3h02mK+cVYvvtnMA6kuDiUzszxVWRnc/Oe3eWzaEr4xuDffHNK7RQcSOJTMzPJSZWXwL396m8enL+HGwb355tDDcl1Sk/CErGZmeaaiMvhuKwwk8EjJzCyvVFQG333ibf705hJuGtKbm4a0nkACh5KZWd6oqAy+8/hM/vzWUr455DBuHNI71yU1OYeSmVkeqB5I3xp6GN8Y3PoCCRxKZmY5V1EZfPvxmTz51lK+ffZh3HBW6wwkcCiZmeVURWXwz4/N4C8zPuI7n+vD186s7XZxrYNDycwsR8orKvnnx2fyPw6kbRxKZmY5UF5Rybcem8lTMz/iu8P68NUzHEjgUDIza3LlFZV887GZPD3zI/5l2OF85YyeuS4pbziUzMyaUPVAuvmcw7n+dAdSdQ4lM7MmUl5RyU2PzuCZtz/mlnMO58sOpE9xKJmZNYHyikpufHQGz779Md8793DGnOZAqolDycwsy7ZWVHLT+Bk8O+tjvn9uX647rUeuS8pbDiUzsyzaWlHJjePf4rlZn3DreX259lQH0o44lMzMsmRrRSXfeOQt/vqOA6m+HEpmZlmwtaKSrz/8Fs/PdiA1hO+nVANJPSTdJ+mJXNdiZs3PlvJKbnj4TZ6f/Qk/GN7PgdQAWQ8lSe9LmiVphqRpNazvKullSXMkzZZ04y5sa5ykUknv1LBumKR5khZIunlH/UTEoogYvbN1mFnrVRVIL8wu4bbz+3HNKd1zXVKz0lSH786MiOW1rCsH/jki3pTUHpguaUJEzKlqIKkA2BgRa6st6xURCzL6uh/4HfBA9YWS2gB3AkOBJcBUSU8BbYCfZvRxTUSUNvgTmlmrt6W8kq89/CYT5pTwr+f346qTHUgNlfPDdxHxcUS8mT5fCxQDnTOanQ78RdKeAJKuA35bQ1+vAitr2MxAYEE6AtoCjAdGRMSsiBie8agzkCSdL2lsWVlZQz6qmbVg1QPph58/woG0k5oilAJ4UdJ0SWN21FBSN2AAMGW7DiIeB14AHpV0KXANcFEDaugMLK72egmfDr7qdXSUdDcwQNItmesj4umIGNOhQ4cGlGBmLdWW8kq++lASSD8acQRXntQt1yU1W01x+O6UiFiaHoKbIGluOqLZjqR9gT8BN0XEmsz1EXGHpPHAXUDPiFiXrYIjYgVwfbb6N7OWY3N5BV976E0mFpfy4xFHcPmJ3XJdUrOW9ZFSRCxN/ywFniQ5lLYdSW1JAumhiPhzTf1IOhXon/ZxWwPLWAp0rfa6S7rMzGynbS6v4KsPpoH0hf4OpEaQ1VCStE968QKS9gHOBt7JaCPgPqA4In5RSz8DgLHACOBqoKOk2xtQylSgt6TukvYARgJPNfTzmJlV2VxewVcefJNJc0u5/Qv9uXzQZ3NdUouQ7ZFSIfCapJnAG8CzEfE8gKTnJB0CnAxcDpyVXjY+Q9K5Gf20Ay6OiIURUQlcAXyQuTFJjwCvA30kLZE0GiAiyoEbSM5LFQOPRcTsbHxgM2v5qgLppbml/OSL/bnMgdRoFBG5rqHZKioqimnTPvXTKzNrwTZtreArD07n5XnL+LcvHsklJxya65KaHUnTI6KopnWeZsjMrJ42ba3g+gen878OpKxxKJmZ1cOmrRV8+Y/TeWX+Mn56wZGMGuhAygaHkplZHTZtrWDMH6fz6vxl/OyCIxnpQMoah5KZ2Q5s2lrBdQ9M47UFy7njS0dx8fFd636T7TSHkplZLaoH0r9/6SguLnIgZZtDycysBpkjpIscSE3CoWRmlmHjliSQ/rZwOT+/8GguPK5LrktqNRxKZmbVbNxSwbUPTOXvC1c4kHLAoWRmltq4pYLRf5jK64tW8B8XHs2XHEhNzqFkZsb2gfSfFx3NBcc6kHLBoWRmrd6GLeWMvn8aU95bwS8uPpovDnAg5YpDycxatQ1byrnm/qm88d5KfnHxMXxhQK33/7Qm4FAys1areiD98p+OYcQxDqRccyiZWau0fnM5V98/lWnvO5DyiUPJzFqd9ZvLufr3U5n2gQMp3ziUzKxVqQqk6R+u4tcjB3D+0YfkuiSrxqFkZq3Gus3lXP37N3jzw9X8euQxDD/KgZRvHEpm1iqs21zOVePe4K3Fq/nNyAGcd9TBuS7JarBbrgswM8s2B1Lz4ZGSmbVoazdt5arfT2XG4tX8dtQAzj3SgZTPPFLKIKmHpPskPZHrWsxs16zdtJUrx73BzMWr+Z0DqVnIaihJel/SLEkzJE2rpc04SaWS3mmE7dXYl6RhkuZJWiDp5h31ERGLImL0rtZiZrlVFUhvLynjd5cM4BwHUrPQFCOlMyPimIgoqmX9/cCw2t4sqUBS+4xlverbl6Q2wJ3AOUA/YJSkfum6IyU9k/EoqM+HMrP8tWbTVq7YFkjHMqy/A6m5yPk5pYh4VVK3HTQ5Hbhe0rkRsVnSdcAFJCFTn74GAgsiYhGApPHACGBORMwChje0ZknnA+f36lVbNppZrqzZtJUr7nuDd5ZWBdJncl2SNcAOR0qSzqr2vHvGugvq0X8AL0qaLmnMzhQYEY8DLwCPSroUuAa4qAFddAYWV3u9JF1WI0kdJd0NDJB0Sy01PR0RYzp06NCAMsws26oH0p2XOpCao7pGSv8BHJs+/1O15wC3An+u4/2nRMTS9JDYBElzI+LVhhYZEXekI5y7gJ4Rsa6hfTRgWyuA67PVv5llR9nG5JDdnI/K+K9Lj+XsIxxIzVFd55RUy/OaXn9KRCxN/ywFniQ5lNZgkk4F+qd93NbAty8FulZ73SVdZmYtRNnGrVxx35Q0kI5zIDVjdYVS1PK8ptfbkbRP1QUKkvYBzgYafIWdpAHAWJLzQFcDHSXd3oAupgK9JXWXtAcwEniqoXWYWX4q27CVy++bwpyP13DXpccxtF9hrkuyXVBXKPWQ9JSkp6s9r3rdvY73FgKvSZoJvAE8GxHPA0h6TtIh6fNHgNeBPpKWSMq8HLsdcHFELIyISuAK4IOaNlhTXxFRDtxAcl6qGHgsImbXUbuZNQNlG7Zy2X1TmPvxWu6+7DiGOJCaPUXUPuCRdPqO3hwRrzR6Rc1IUVFRTJtW48+vzCzLqgJp3idrufvyYznrcAdScyFpem0/E9rhhQ6ZoSOpLcm5naXpeSIzsya3esMWLrtvCvM/Wcd/X34cZx7unxe2FHVdEn63pCPS5x2AmcADwFuSRjVBfWZm21m9YQuX3utAaqnqOqd0arXzL1cD8yPiSOA44LtZrczMLENVIL1buo7/vsKB1BLVFUpbqj0fCvwFICI+yVZBZmY1WbV+C5fckwTS2MuP48w+DqSWqK4fz66WNJzkdz0nA6MBJO0O7J3l2szMgCSQLr13CguWreOeK4o4/bBOuS7JsqSuUPoy8BvgM8BN1UZIg4Fns1mYmRnAyjSQFjqQWoW6rr6bTw0zeEfECyS/+zEzy5qV67dwyT2TeW/5eu69oojTHEgt3g5DSdJvdrQ+Ir7RuOWYmSW2C6Qrizi1twOpNajr8N31JFMDPQZ8RD3muzMz21Ur1m3m0nun8N7y9dx35fGc0vugXJdkTaSuUDqY5DYR/wSUA48CT0TE6izXZWat1PJ1m7n0nim8v8KB1Brt8JLwiFgREXdHxJkkv1PaH5gj6fKmKM7MWpfl6zZzyT2T+WDlesZd5UBqjep151lJxwKjSH6r9FdgejaLMrPWpyqQPly5gXFXHs9JvRxIrVFdFzr8CDiPZHbt8cAt6azbZmaNZtnaJJAWr9rAuKuO56SeDqTWqq6R0q3Ae8DR6ePfJEFywUNExFHZLc/MWrqqQFqyaiO/v2ogJ/bsmOuSLIfqCqW67plkZrbTStdu4pJ7prB01UZ+f/XxDOrhQGrt6vrxbG0309uN5BxTjevNzOpSunYTo8ZO5qPVmxxItk1dt67YT9Itkn4n6Wwlvg4sAi5umhLNrKUpXZME0sdlm7jfgWTV1HX47o/AKpJbjF8LfI/kfNIXImJGdkszs5aodM0mRt4zmU/KNnH/1QMZ2P3AXJdkeaSuUOqR3j8JSfcCHwOHRsSmrFdmZi2OA8nqUtf9lLZWPYmICmCJA8nMdkbJmk2MHDuZkrJN/OEaB5LVrK6R0tGS1qTPBeydvq66JHy/rFaXI5J6AN8HOkTEhbmux6y5+6RsE6PumUzpmiSQiro5kKxmdU0z1CYi9ksf7SNi92rPGy2QJL0vaZakGZKm7UI/4ySVSnqnhnXDJM2TtEDSzTvqJyIWRcTona3DzP7BgWQNUa9phprImRGxvKYVkgqAjRGxttqyXhGxIKPp/cDvgAcy3t8GuJNkmqQlwFRJTwFtgJ9m9HFNRJTuygcxs8THZRsZNXYyy9dt4YHRAznusw4k27G6zinli9OBv0jaE0DSdcBvMxtFxKvAyhrePxBYkI6AtpBMmTQiImZFxPCMR52BJOl8SWPLysp26UOZtWQfl21kZBpIf7jGgWT1ky+hFMCLkqZLGvOplRGPk9zp9lFJlwLXkNxSo746A4urvV6SLquRpI6S7gYGSLqlhnqejogxHTp0aEAJZq3HR6uTQFq5bYR0QK5LsmYiXw7fnRIRS9PDdBMkzU1HPdtExB2SxgN3AT0jYl22iomIFSQ3ODSzBqoKpFXrk0AacKgDyeovL0ZKEbE0/bMUeJLkcNt2JJ0K9E/X39bATSwFulZ73SVdZmaNaKkDyXZRzkNJ0j6S2lc9B84muQV79TYDgLHACJKbDXaUdHsDNjMV6C2pu6Q9gJHAU41Rv5klkkB6nVUbtvDHa09wINlOyXkoAYXAa5JmAm8Az0bE8xlt2gEXR8TCiKgErqCGyWAlPUIyJVIfSUskjQZI7wF1A8l5qWLgsYiYnbVPZNbKLFm1gZFjX2f1hq08OPoEjum6f65LsmZKEZHrGpqtoqKimDZtp39WZdYiJIE0mbKNSSAd7UCyOkiaHhFFNa3LlwsdzKwZWrxyA6PumcyajVt56NoTOKrL/rkuyZo5h5KZ7ZTFK5MR0tpNW3no2kEc2cU/kbBdlw/nlMysmakKpHWbyx1I1qg8UjKzBtk+kE6gf2cHkjUeh5KZ1duHK5Kr7NZvqXAgWVb48J2Z1csHK9YzcuzrbNjqQLLs8UjJzOqUBNJkNqaBdMQhDiTLDoeSme3Q+8vXM+qeyWzaWsHD1w6i3yEt8t6eliccSmZWq/eXJyOkzeUVPORAsibgUDKzGr23fD2jxk5mS0UlD183iL4HO5As+xxKZvYp7y1PLmrYWhE8fN0JHP4ZB5I1DYeSmW1n0bJ1jLpnsgPJcsKhZGbbLFq2jpFjJ1NRGTxy3SD6fKZ9rkuyVsa/UzIzABZWC6SHHUiWIx4pmRkLl61j1NjJVEbwyJhBHFboQLLccCiZtXILSpNzSBHJIbveDiTLIYeSWSu2oHQto+6ZQgQOJMsLDiWzVurdkiSQAMaPOYFeBQ4kyz1f6GDWCiWBNBlwIFl+cSiZtTLz00CSxPgxgxxIllccShkk9ZB0n6Qncl2LWWObX7KWUWMns9u2QNo31yWZbSfroSSpjaS3JD1Ty/obJb0jabakm3ZxW+MklUp6J2P5MEnzJC2QdPOO+oiIRRExelfqMMtH8z5JAqnNbuKRMYPo2cmBZPmnKUZKNwLFNa2Q1B+4DhgIHA0Ml9Qro02BpPYZy7ZrU839wLCMtm2AO4FzgH7AKEn90nVHSnom41HQ0A9olu/mfbKWS+6ZzO5tkhGSA8nyVVZDSVIX4Dzg3lqa9AWmRMSGiCgHXgEuyGhzOvAXSXumfV4H/LamziLiVWBlxuKBwIJ0BLQFGA+MSNvPiojhGY/Senyu8yWNLSsrq6upWc7N/WQNo7YF0on0cCBZHsv2SOlXwHeBylrWvwOcKqmjpHbAuUDX6g0i4nHgBeBRSZcC1wAXNaCGzsDiaq+XpMtqlNZyNzBA0i01tYmIpyNiTIcOvvum5bfij9dwyT1T2KPNbowfcyLdD9on1yWZ7VDWfqckaThQGhHTJZ1RU5uIKJb078CLwHpgBlBRQ7s7JI0H7gJ6RsS6bNUdESuA67PVv1lTSQJpMnvu3obxYwbRzYFkzUA2R0onA5+X9D7JIbOzJD2Y2Sgi7ouI4yLiNGAVMD+zjaRTgf7Ak8BtDaxjKduPvrqky8xarDkfJYG0V1sHkjUvWRspRcQtwC0A6Ujp2xFxWWY7SQURUSrpUJLzSYMy1g8AxgLDgfeAhyTdHhG31rOUqUBvSd1JwmgkcMlOfSizPLZm01ZembeMicUlTJxTwn57t2X8mEF8tqMDyZqPnEwzJOk54NqI+Aj4k6SOwFbgaxGxOqN5O+DiiFiYvvcK4Kpa+n0EOAM4SNIS4LaIuE/SDSTnpdoA4yJiduN/KrOmt3jlhiSEikuYsmgl5ZXBgfvswbD+B3PTkN50PbBdrks0axBFRK5raLaKiopi2rRpuS7DWpHKymDGktVMnFPCpOJS5pWsBaBXwb4M6VvIkL4FDDj0ANrsphxXalY7SdMjoqimdZ6Q1SzPbdhSzmvvLmdicQkvzS1l+bottNlNHN/tAG49ry9D+hb6nJG1GA4lszxUsmYTE4uT0dDfFixnc3kl7ffcndP7dGJov0LOOKyADu3a5rpMs0bnUDLLAxHBnI/XMHFOKZPmlvD2kuSH2V0P3JtLTjiUIX0LOb7bgeyxu6ertJbNoWSWI5vLK5i8aGV6fqiEj8o2IcExXffnO5/rw9B+hfQu2BfJ54es9XAomTWhleu38PLcUiYWl/Dq/GWs31LB3m3bcGrvg7hpyGGceXgBndrvmesyzXLGoWSWRRHBwmXr0/NDJUz/YBWVAYX77cmIAZ0Z0reAk3oexF5t2+S6VLO84FAya2TlFZVM+2BVclhubinvLV8PQL+D9+OGs3ozpG8B/Q/pwG6+bNvsUxxKZo1gzaatvDp/GRPnlPDyvGWUbdzKHm1248SeHbnm5G6c1beQzvvvnesyzfKeQ8lsJ1XNpjCpuJTJi1ZQXhkc0K4tQ/oWMrRfAaf07sS+e/qvmFlD+G+MWT1VVgYzl6zeFkRzP0lmU+jZaR9Gn9qdoX0LPZuC2S5yKJntwMYtFby2YPm280PL123ebjaFwX0LfY8is0bkUDLLULJmE5OKS5lUXMJrGbMpDOlbyBl9OrF/uz1yXaZZi+RQslYvIij+eO22y7ZnprMpdDlgb0YNPJSh/TybgllTcShZq7S5vIIpi1ZuOz+0dPXG7WZTGNK3kMMKPZuCWVNzKFmrUTWbwqS5JbwyL5lNYa+2u3Fq707cOLi3Z1MwywMOJWvRFi5bt+3eQ9M+WEllQEH7Pfn8MZ0Z2s+zKZjlG4eStShVsylMKi5hYnHGbApn9mJIv0LPpmCWxxxK1uyt3bSVV+YvY1JxKS/NLd02m8Igz6Zg1uw4lKxZWrxyA5OKk98OTV60gq0VyWwKg/sWMLRvIace5tkUzJoj/621ZqGyMnh7aRkT55Qwsbhku9kUrjm5O0P6FXKsZ1Mwa/YcSpa3qmZTqBoRLVubzKZQ9FnPpmDWUjmUMkjqAXwf6BARF+a6ntamdM0mJs1NZlP4v3f/MZvCaX06MdSzKZi1eFkPJUltgGnA0ogYXsP6bwLXAgHMAq6OiE07sZ1xwHCgNCL6Z6wbBvwaaAPcGxE/q62fiFgEjJb0RENrsIaLCOZ+snbbYbnM2RSG9C1kYHfPpmDWWjTFSOlGoBjYL3OFpM7AN4B+EbFR0mPASOD+am0KgI0Rsbbasl4RsSCju/uB3wEPZGyjDXAnMBRYAkyV9BRJQP00o49rIqJ0Jz6jNcCW8komL1qx7bLtpas3Av+YTWFw3wL6FLb3bApmrVBWQ0lSF+A84CfAt3ZQw96StgLtgI8y1p8OXC/p3IjYLOk64ALgnOqNIuJVSd1q6H8gsCAdASFpPDAiIn5KMrKyJrBq/RZenlfKpOJSXpm/jHWby9mr7W6c0qsT3xjcizMPL6Cg/V65LtPMcizbI6VfAd8F2te0MiKWSvoP4ENgI/BiRLyY0eZxSd2BRyU9DlxDMuqpr87A4mqvlwAn1NZYUkeSEB0g6ZY0vDLbnA+c36tXrwaU0fosWraOicUlTJyz/WwK5x99CEP6FnByL8+mYGbby1ooSao6vzNd0hm1tDkAGAF0B1YDj0u6LCIerN4uIu5IRzh3AT0jYl226o6IFcD1dbR5Gni6qKjoumzV0RyVV1Qy/YNVTJpbysQ5JSxKZ1Pom86mMLhvIUd29mwKZla7bI6UTgY+L+lcYC9gP0kPRsRl1doMAd6LiGUAkv4MnARsF0qSTgX6A08CtwE3NKCOpUDXaq+7pMusEazdtJVX5yeXbb80r5TVG7bSto0Y1KMjV53cjbMOL6DLAe1yXaaZNRNZC6WIuAW4BSAdKX07I5AgOWw3SFI7ksN3g0mu1NtG0gBgLMn5n/eAhyTdHhG31rOUqUDv9BDgUpILKS7Zmc9kiSWrNjCpuJSJxSXbzaZw1uEFDOlbyKm9D6L9Xm1zXaaZNUM5+Z2SpOeAayNiSnrp9ZtAOfAWSQBV1w64OCIWpu+9Ariqhj4fAc4ADpK0BLgtIu6LiHJJNwAvkFxxNy4iZmfnk7VMVbMpTCouYcKcf8ym0COdTWFw30KOPXR/dm/jy7bNbNcoInJdQ7NVVFQU06ZNq7thM7RxSwV/W7CcSXOTy7aXrd3MboKibgcytG8hg/sW0KPTvrku08yaIUnTI6KopnWe0cG2KV27iZfSw3KvLVjOpq2V7Lvn7pzepxND+hZwxmEFHLCPZ1Mws+xxKLViVbMpTCouYUJxKTMXrwag8/57M/J4z6ZgZk3PodTKbCmvZMp7K5hUXMqEOSXbzabw7bMPY0i/Qs+mYGY541BqBVZvSGZTmDjn07MpfP2sXpx1eAEF+3k2BTPLPYdSC7Vo2bpkNFRcwvQPVlFRGXRqvyfnH30wQ/oWclLPg9h7D8+mYGb5xaHUQpRXVPLmh6vT80MlLFr2j9kUvnpGT4Z4NgUzawYcSs3Yus3lvDp/GRPnlPDyvFJWVZtN4coTuzG4r2dTMLPmxaHUzCxdvXHbj1inLFrJlopK9m/XlrP6FDCkn2dTMLPmzaGU5yorg1lVsykUl1L88RogmU3hqpO7McSzKZhZC+JQykObtiazKUwsLmFScSml1WZT+N65hzO4byE9PZuCmbVADqU8Ubp2Ey/PLWXCnFJeW7DsH7MpHNaJIf08m4KZtQ4OpRyJCOaVrGXinGRuuRnVZlP4p6KuDOlXyAndO3o2BTNrVRxKOTBl0Qr++fGZLFmVzKZwdDqbwuC+hRz+Gc+mYGatl0MpBzofsDeHf6Y9N5zp2RTMzKpzKOVAlwPace+Vx+e6DDOzvOMTFmZmljccSmZmljccSmZmljccSmZmljccSmZmljccSmZmljccSmZmljccSmZmljcUEbmuodmStAz4YCfffhCwvBHLaUz5WpvrahjX1TCuq2F2pa7PRkSnmlY4lHJE0rSIKMp1HTXJ19pcV8O4roZxXQ2Trbp8+M7MzPKGQ8nMzPKGQyl3xua6gB3I19pcV8O4roZxXQ2Tlbp8TsnMzPKGR0pmZpY3HEpmZpY3HEpZIGmcpFJJ79SyXpJ+I2mBpLclHVtt3ZWS3k0fVzZhTZemtcyS9HdJR1db9366fIakaY1VUwNqO0NSWbr9GZJ+UG3dMEnz0u/y5iau6zvVanpHUoWkA9N1WfnOJHWV9LKkOZJmS7qxhja52L/qU1eT72P1rKvJ96961tXk+1fa916S3pA0M63thzW02VPSo+n3MkVSt2rrbkmXz5P0uQYXEBF+NPIDOA04FninlvXnAn8FBAwCpqTLDwQWpX8ekD4/oIlqOqlqW8A5VTWlr98HDsrh93UG8EwNy9sAC4EewB7ATKBfU9WV0fZ84KVsf2fAwcCx6fP2wPzMz5yj/as+dTX5PlbPupp8/6pPXbnYv9K+BeybPm8LTAEGZbT5KnB3+nwk8Gj6vF/6Pe0JdE+/vzYN2b5HSlkQEa8CK3fQZATwQCQmA/tLOhj4HDAhIlZGxCpgAjCsKWqKiL+n2wSYDHRpjO3WRz2+r9oMBBZExKKI2AKMJ/luc1HXKOCRxtp2bSLi44h4M32+FigGOmc0y8X+VWddudjH6vl91SZr+9dO1NUk+1daT0TEuvRl2/SReUXcCOAP6fMngMGSlC4fHxGbI+I9YAHJ91hvDqXc6AwsrvZ6SbqstuVNbTTJ/2lXCeBFSdMljclBPQAnpocT/irpiHRZXnxfktqR/OP+p2qLs/6dpYdMBpD8n2x1Od2/dlBXdU2+j9VRV872r7q+r1zsX5LaSJoBlJL8j0yt+1hElANlQEca4TvbfSdrthZK0pkk/2CcUm3xKRGxVFIBMEHS3HQU0VTeJJkra52kc4G/AL2bcPt1OR/4W0RUH1Vl9TuTtC/JP1I3RcSaxup3V9WnrlzsY3XUlbP9q57/HZt8/4qICuAYSfsDT0rqHxE1nlttbB4p5cZSoGu1113SZbUtbxKSjgLuBUZExIqq5RGxNP2zFHiSBg7Hd1VErKk6nBARzwFtJR1Ejr+vakaScWglm9+ZpLYk/5A9FBF/rqFJTvavetSVk32srrpytX/V5/tKNen+lbGd1cDLfPow77bvRtLuQAdgBY3xnWXjRJkfAdCN2k/cn8f2J6LfSJcfCLxHchL6gPT5gU1U06Ekx39Pyli+D9C+2vO/A8Oa+Pv6DP/4ofdA4MP0u9ud5GR9d/5xIvqIpqorXd+B5LzTPk3xnaWf+wHgVzto0+T7Vz3ravJ9rJ51Nfn+VZ+6crF/pX12AvZPn+8N/B8wPKPN19j+QofH0udHsP2FDoto4IUOPnyXBZIeIbmi5yBJS4DbSE4WEhF3A8+RXCG1ANgAXJ2uWynpx8DUtKsfxfZD9mzW9AOSY8L/lZyvpDySGYALSYbvkPwlfTginm+MmhpQ24XAVySVAxuBkZH8DSiXdAPwAsmVUuMiYnYT1gXwReDFiFhf7a3Z/M5OBi4HZqXH/AG+R/IPfs72r3rWlYt9rD515WL/qk9d0PT7FyRXBv5BUhuSo2mPRcQzkn4ETIuIp4D7gD9KWkASmiPTumdLegyYA5QDX4vkUGC9eZohMzPLGz6nZGZmecOhZGZmecOhZGZmecOhZGZmecOhZGZmecOXhJvlGUkVwCySy8/LSX7P8suIqMxpYWZNwKFkln82RsQxAOk0Mg8D+5H8TmqXSGrT0N+NmDUlH74zy2ORTCMzBrhBiTaSfi5pqpJ7E30ZQNJukv5L0lxJEyQ9J+nCdN37kv5d0pvARZLOlvS6pDclPZ7Ov4ak4yS9kk7y+UI6s7hZk3IomeW5iFhEMqNAAclEpmURcTxwPHCdpO7ABSRTIvUjmSngxIxuVkTEscBE4FZgSPp6GvCtdB623wIXRsRxwDjgJ9n+bGaZfPjOrHk5GziqahREMjdab5IZtx9Pzzt9IunljPc9mv45iCS4/pZOU7MH8DrQB+hPMuM0JCH4cRY/h1mNHEpmeU5SD6CC5N42Ar4eES9ktDm3jm6q5k4Tyf1xRmW8/0hgdkRkjrDMmpQP35nlMUmdgLuB36WThL5AMnlo23T9YZL2Af4GfCk9t1RIMpFsTSYDJ0vqlb5/H0mHAfOATpJOTJe3rXazO7Mm45GSWf7ZO505uuqS8D8Cv0jX3Uty7uhNJcfZlgFfILkvz2CS2ZkXk9y4riyz44hYJukq4BFJe6aLb42I+ekhwd9I6kDyb8OvgEabdd2sPjxLuFkLIWnfSO6e2hF4Azg5Ij7JdV1mDeGRklnL8Ux6++o9gB87kKw58kjJzMzyhi90MDOzvOFQMjOzvOFQMjOzvOFQMjOzvOFQMjOzvPH/AWecE6exSe5LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import gc\n",
    "rmses = []\n",
    "degrees = [1, 2, 3]\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    poly_reg = linear_model.LogisticRegression(penalty='l2', C = 0.01)\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    print(\"Fit Deg: \", deg)\n",
    "    poly_predict = poly_reg.predict(x_poly_test)\n",
    "    print(\"Predict Deg: \", deg)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    \n",
    "    print(\"Training Set Results\")\n",
    "    print(confusion_matrix(y_train,predict_train))\n",
    "    print(classification_report(y_train,predict_train))\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "    \n",
    "    del poly_features\n",
    "    del x_poly_train\n",
    "    del poly_reg\n",
    "    del x_poly_test\n",
    "    del poly_predict\n",
    "    gc.collect()\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb0ded-2cff-4252-a196-839ab7a9f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# # create transform\n",
    "# trans = PolynomialFeatures(degree=min_deg)\n",
    "# # fit and transform\n",
    "# X = trans.fit_transform(X)\n",
    "# print('Degree: %d, Features: %d' % (min_deg, X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0432f-db23-4621-9bac-0e74fccc938a",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
