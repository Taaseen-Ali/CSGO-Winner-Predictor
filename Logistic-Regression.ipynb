{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df10e46-3ecd-43b1-9465-28c3591509a8",
   "metadata": {},
   "source": [
    "# CSGO Match Prediction with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c3766f-a685-4de8-9e54-55260aeb09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65df54f6-f145-43e3-92e0-9ccc01c2b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas to try\n",
    "# ============\n",
    "# - higher learning rate, higher c, with one hot encoding\n",
    "# - polyfit with no one-hot\n",
    "# - polyfit with one hot\n",
    "# - psuedo one-hot encoding vs summing winner data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355d01f-cd67-45d7-8e1b-bc834e266529",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3066d4-c078-4497-a50c-f2f5e1f25e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./economy.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33cd1b4-a7ac-40cb-b939-404d905ef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = df.T.apply(pd.Series.last_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4426f355-9936-459c-9893-a05a88c3e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_col = []\n",
    "winnerarr = np.array(winners)\n",
    "for i in range(df.shape[0]):\n",
    "    winners_col.append(df[winnerarr[i]][i])\n",
    "    #winners_col.append(df[\"team_\" + str(int(df[winnerarr[i]][i]))][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d69670e7-7527-465b-bb96-33d755fcd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match_winner'] = winners_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bb54f4-501e-40ff-88bc-c80b07aec1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_win_col_names = [\n",
    " '16_winner',\n",
    " '17_winner',\n",
    " '18_winner',\n",
    " '19_winner',\n",
    " '20_winner',\n",
    " '21_winner',\n",
    " '22_winner',\n",
    " '23_winner',\n",
    " '24_winner',\n",
    " '25_winner',\n",
    " '26_winner',\n",
    " '27_winner',\n",
    " '28_winner',\n",
    " '29_winner',\n",
    " '30_winner']\n",
    "\n",
    "df = df.drop(columns=round_win_col_names)\n",
    "df = df.drop(columns=[\"best_of\", \"date\", \"t2_start\"])\n",
    "df = df.drop(columns=[\"match_id\", \"event_id\"])\n",
    "\n",
    "droprounds = ['16_t1', '17_t1', '18_t1', '19_t1', '20_t1', '21_t1', '22_t1', '23_t1', '24_t1', '25_t1', '26_t1', '27_t1', '28_t1', '29_t1', '30_t1', '16_t2', '17_t2', '18_t2', '19_t2', '20_t2', '21_t2', '22_t2', '23_t2', '24_t2', '25_t2', '26_t2', '27_t2', '28_t2', '29_t2', '30_t2']\n",
    "df = df.drop(columns=droprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b596710a-c30b-4819-ba79-52b0d9f898e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c8a893-3b5f-41b2-82ce-c9a0d591c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-072520d650ff>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_1'] = X['team_1'].replace(team_to_num)\n",
      "<ipython-input-9-072520d650ff>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['team_2'] = X['team_2'].replace(team_to_num)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>_map</th>\n",
       "      <th>1_t1</th>\n",
       "      <th>2_t1</th>\n",
       "      <th>3_t1</th>\n",
       "      <th>4_t1</th>\n",
       "      <th>5_t1</th>\n",
       "      <th>6_t1</th>\n",
       "      <th>7_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>7_winner</th>\n",
       "      <th>8_winner</th>\n",
       "      <th>9_winner</th>\n",
       "      <th>10_winner</th>\n",
       "      <th>11_winner</th>\n",
       "      <th>12_winner</th>\n",
       "      <th>13_winner</th>\n",
       "      <th>14_winner</th>\n",
       "      <th>15_winner</th>\n",
       "      <th>t1_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2678</td>\n",
       "      <td>1226</td>\n",
       "      <td>0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>22100.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2678</td>\n",
       "      <td>1226</td>\n",
       "      <td>1</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>28500.0</td>\n",
       "      <td>31900.0</td>\n",
       "      <td>31700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2678</td>\n",
       "      <td>1226</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>23150.0</td>\n",
       "      <td>21850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1226</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>18050.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>25850.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>27250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1226</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24500.0</td>\n",
       "      <td>27550.0</td>\n",
       "      <td>29350.0</td>\n",
       "      <td>31950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43229</th>\n",
       "      <td>913</td>\n",
       "      <td>2316</td>\n",
       "      <td>9</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>26750.0</td>\n",
       "      <td>27450.0</td>\n",
       "      <td>26950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43230</th>\n",
       "      <td>57</td>\n",
       "      <td>798</td>\n",
       "      <td>4</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>17400.0</td>\n",
       "      <td>22050.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>25650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43231</th>\n",
       "      <td>1169</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>29150.0</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>8750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43232</th>\n",
       "      <td>2923</td>\n",
       "      <td>1222</td>\n",
       "      <td>2</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>22950.0</td>\n",
       "      <td>25750.0</td>\n",
       "      <td>26850.0</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43233</th>\n",
       "      <td>2134</td>\n",
       "      <td>2505</td>\n",
       "      <td>8</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>18950.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43234 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_1  team_2  _map    1_t1     2_t1     3_t1     4_t1     5_t1  \\\n",
       "0        2678    1226     0  4350.0   1100.0  22100.0   9350.0  25750.0   \n",
       "1        2678    1226     1  3900.0   7400.0  23250.0  28500.0  31900.0   \n",
       "2        2678    1226     2  4150.0  14300.0   2000.0  24800.0   9000.0   \n",
       "3        1226      57     1  4150.0  18050.0  21000.0  25850.0  25000.0   \n",
       "4        1226      57     0  4200.0  10000.0  22000.0  24500.0  27550.0   \n",
       "...       ...     ...   ...     ...      ...      ...      ...      ...   \n",
       "43229     913    2316     9  4250.0   7400.0  17200.0  18500.0  26750.0   \n",
       "43230      57     798     4  4250.0   1600.0  24250.0  17400.0  22050.0   \n",
       "43231    1169    1500     2  4350.0   7650.0  20000.0  21500.0  29150.0   \n",
       "43232    2923    1222     2  4150.0  11800.0   1200.0  22950.0  25750.0   \n",
       "43233    2134    2505     8  4100.0  17700.0  18950.0  13200.0  24000.0   \n",
       "\n",
       "          6_t1     7_t1  ...  7_winner  8_winner  9_winner  10_winner  \\\n",
       "0      10400.0  24600.0  ...       2.0       2.0       1.0        2.0   \n",
       "1      31700.0  18950.0  ...       2.0       1.0       1.0        2.0   \n",
       "2      23150.0  21850.0  ...       1.0       2.0       2.0        2.0   \n",
       "3      25000.0  27250.0  ...       1.0       1.0       1.0        1.0   \n",
       "4      29350.0  31950.0  ...       2.0       1.0       1.0        1.0   \n",
       "...        ...      ...  ...       ...       ...       ...        ...   \n",
       "43229  27450.0  26950.0  ...       2.0       1.0       2.0        2.0   \n",
       "43230   6600.0  25650.0  ...       1.0       1.0       1.0        1.0   \n",
       "43231  26900.0   8750.0  ...       2.0       2.0       2.0        1.0   \n",
       "43232  26850.0  27850.0  ...       1.0       1.0       2.0        1.0   \n",
       "43233  20550.0  14500.0  ...       1.0       1.0       1.0        2.0   \n",
       "\n",
       "       11_winner  12_winner  13_winner  14_winner  15_winner  t1_t  \n",
       "0            2.0        2.0        2.0        2.0        2.0     1  \n",
       "1            2.0        2.0        2.0        2.0        2.0     0  \n",
       "2            2.0        2.0        2.0        2.0        2.0     1  \n",
       "3            1.0        1.0        1.0        1.0        1.0     1  \n",
       "4            1.0        1.0        1.0        1.0        1.0     0  \n",
       "...          ...        ...        ...        ...        ...   ...  \n",
       "43229        2.0        2.0        2.0        2.0        2.0     1  \n",
       "43230        1.0        1.0        2.0        2.0        2.0     1  \n",
       "43231        1.0        2.0        2.0        1.0        1.0     0  \n",
       "43232        1.0        1.0        1.0        1.0        1.0     1  \n",
       "43233        1.0        1.0        1.0        1.0        1.0     1  \n",
       "\n",
       "[43234 rows x 49 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(colnames)\n",
    "xnames = colnames[:len(colnames) - 1]\n",
    "#print(xnames)\n",
    "X = df[xnames]\n",
    "\n",
    "set_of_teams = set(list(X['team_1']) + list(X['team_2']))\n",
    "team_to_num = dict(zip(set_of_teams, range(len(set_of_teams))))\n",
    "\n",
    "#Replace team's name with their number\n",
    "X['team_1'] = X['team_1'].replace(team_to_num)\n",
    "X['team_2'] = X['team_2'].replace(team_to_num)\n",
    "y = df[\"match_winner\"]\n",
    "\n",
    "#Convert from t1_start to t1_t and convert from t,ct to binary\n",
    "X['t1_t'] = X['t1_start'].apply(lambda x: 1 if x == 't' else 0)\n",
    "X = X.drop('t1_start', axis=1)\n",
    "\n",
    "#Replace map names with numbers\n",
    "map_to_num = dict(zip(X['_map'].unique(), range(len(X['_map'].unique()))))\n",
    "X['_map'] = X['_map'].replace(map_to_num)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc479b72-1d69-4df3-9bac-b85a3f3744d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "43229    2.0\n",
       "43230    1.0\n",
       "43231    1.0\n",
       "43232    1.0\n",
       "43233    1.0\n",
       "Name: match_winner, Length: 43234, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1414a-0b65-4319-845e-32b4c2cfaa86",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb8be17-2722-4233-a204-b5c38fb1c1d6",
   "metadata": {},
   "source": [
    "## One-Hot Conversion (Encoding Teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e67491-ae60-46fd-bd5a-976f9f23b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the team names back into strings again\n",
    "# num_to_team = dict(zip(range(len(set_of_teams)), set_of_teams))\n",
    "# all_teams = [num_to_team[i] for i in range(len(set_of_teams))]\n",
    "\n",
    "# # Extract the team data from the original DataFrame\n",
    "# team_1_arr = np.array(X[\"team_1\"])\n",
    "# team_2_arr = np.array(X[\"team_2\"])\n",
    "\n",
    "# # Create the one-hot vectors for each row of the data, one for each team\n",
    "# one_hot_t1 = np.zeros((team_1_arr.size, len(num_to_team)))\n",
    "# one_hot_t1[np.arange(team_1_arr.size), team_1_arr] = 1\n",
    "\n",
    "# one_hot_t2 = np.zeros((team_2_arr.size, len(num_to_team)))\n",
    "# one_hot_t2[np.arange(team_2_arr.size), team_2_arr] = 1\n",
    "\n",
    "# # Combine the matrix of one-hot vectors for team_1 and team_2 together to create a single matrix\n",
    "# one_hot = np.hstack((one_hot_t1, one_hot_t2))\n",
    "\n",
    "# # Turn the numpy array into a pandas DataFrame and add it to the dataset\n",
    "# one_hot_df = pd.DataFrame(one_hot, columns = [\"team_1_%s\" %(i) for i in all_teams] + [\"team_2_%s\" %(i) for i in all_teams])\n",
    "# X = X.drop(columns = [\"team_1\", \"team_2\"])\n",
    "# X = X.join(one_hot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bf600-5b52-4c54-84c7-b2aa15ed8cff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59aed415-2eab-4e7e-aed0-e170fd855334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a5eef-ed81-47a7-9c64-9d633d677c5c",
   "metadata": {},
   "source": [
    "## LogReg w/ No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c32b784-1f9b-4d3d-8b8b-c593f86a5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_none = linear_model.LogisticRegression(penalty='none') # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2014dae8-a990-40ee-8194-cff676aeaa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_none.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13ac3b4-084e-4cfc-bef1-53ea9f1d019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.776020\n"
     ]
    }
   ],
   "source": [
    "yhat = logreg_ridge_none.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f341d4d7-7885-4aac-a1fa-ed7e3ffd3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 1.0\n",
      "Accuracy on the test data is 0.776020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>-0.004190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>-0.008733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.029631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.051119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>-0.029782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.047741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>0.005768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>0.002770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.021729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.018653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>-0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>-0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.013140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.020567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.062015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.015116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.025686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>-0.015314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.034138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.023599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>-0.006005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.007974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>-0.011548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>-0.017059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.012059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>-0.005062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.012264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>-0.028227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.023922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.017467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.229450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.265816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.215515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.273191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.317525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.272848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.296857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.297046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.284626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.272396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.289748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.290809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.267149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.264344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.290269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.122204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1 -0.004190\n",
       "1      team_2  0.003690\n",
       "2        _map -0.008733\n",
       "3    t1_start  0.029631\n",
       "4        1_t1 -0.051119\n",
       "5        2_t1 -0.029782\n",
       "6        3_t1 -0.047741\n",
       "7        4_t1  0.005768\n",
       "8        5_t1  0.002770\n",
       "9        6_t1  0.021729\n",
       "10       7_t1 -0.018653\n",
       "11       8_t1 -0.003937\n",
       "12       9_t1  0.004715\n",
       "13      10_t1  0.003145\n",
       "14      11_t1 -0.000407\n",
       "15      12_t1 -0.013140\n",
       "16      13_t1 -0.020567\n",
       "17      14_t1 -0.062015\n",
       "18      15_t1  0.015116\n",
       "19       1_t2  0.025686\n",
       "20       2_t2 -0.015314\n",
       "21       3_t2  0.034138\n",
       "22       4_t2  0.023599\n",
       "23       5_t2 -0.006005\n",
       "24       6_t2  0.007974\n",
       "25       7_t2 -0.011548\n",
       "26       8_t2 -0.017059\n",
       "27       9_t2  0.012059\n",
       "28      10_t2 -0.005062\n",
       "29      11_t2  0.012264\n",
       "30      12_t2 -0.028227\n",
       "31      13_t2  0.023922\n",
       "32      14_t2  0.017467\n",
       "33      15_t2  0.229450\n",
       "34   1_winner  0.265816\n",
       "35   2_winner  0.215515\n",
       "36   3_winner  0.273191\n",
       "37   4_winner  0.317525\n",
       "38   5_winner  0.272848\n",
       "39   6_winner  0.296857\n",
       "40   7_winner  0.297046\n",
       "41   8_winner  0.284626\n",
       "42   9_winner  0.272396\n",
       "43  10_winner  0.289748\n",
       "44  11_winner  0.290809\n",
       "45  12_winner  0.267149\n",
       "46  13_winner  0.264344\n",
       "47  14_winner  0.290269\n",
       "48  15_winner -0.122204"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_none.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_none.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f48c219c-bcec-439a-8536-6784f2326e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4592, 1221],\n",
       "       [1200, 3796]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463a3448-5b93-43ea-9ce2-82b90d5d2f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749 (0.007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_none, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31dcf236-c624-4cd7-9e6e-8f364706842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7899535523825908\n",
      "recal:  0.7928176795580111\n",
      "fscore:  0.7913830245583799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b26bf-8f1b-4c77-a5c4-2098bf1e519f",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4238f27d-d1c3-4953-87b7-f0816e9838e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l1 = linear_model.LogisticRegression(solver='liblinear', penalty='l1',warm_start=True, C = 0.01) # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d564e0-74fe-43b5-8d02-d8ac2edd6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='l1', solver='liblinear', warm_start=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af83e63-6336-4469-812c-5e34f23adcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.775742\n"
     ]
    }
   ],
   "source": [
    "yhat_l1 = logreg_ridge_l1.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l1 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f84406b-90e7-4af7-a091-2931d5b4a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 0.01\n",
      "Accuracy on the test data is 0.775742\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.012943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.036035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.007493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.014083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.008606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.013045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.051593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.051042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.003366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.008865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.011685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.020637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.007291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.179152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.268573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.247320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.268070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.293484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.248180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.271984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.263837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.255270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.272229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.265944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.253833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.259902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.269040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.087652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1  0.000000\n",
       "1      team_2  0.000000\n",
       "2        _map  0.000000\n",
       "3    t1_start  0.012943\n",
       "4        1_t1 -0.036035\n",
       "5        2_t1  0.000000\n",
       "6        3_t1 -0.007493\n",
       "7        4_t1  0.000000\n",
       "8        5_t1  0.000000\n",
       "9        6_t1  0.000000\n",
       "10       7_t1 -0.014083\n",
       "11       8_t1  0.000000\n",
       "12       9_t1  0.000000\n",
       "13      10_t1  0.000000\n",
       "14      11_t1  0.000000\n",
       "15      12_t1 -0.008606\n",
       "16      13_t1 -0.013045\n",
       "17      14_t1 -0.051593\n",
       "18      15_t1  0.000000\n",
       "19       1_t2  0.051042\n",
       "20       2_t2  0.000000\n",
       "21       3_t2  0.005547\n",
       "22       4_t2  0.008675\n",
       "23       5_t2  0.000000\n",
       "24       6_t2  0.003366\n",
       "25       7_t2  0.000000\n",
       "26       8_t2  0.000000\n",
       "27       9_t2  0.008865\n",
       "28      10_t2  0.000000\n",
       "29      11_t2  0.011685\n",
       "30      12_t2  0.000000\n",
       "31      13_t2  0.020637\n",
       "32      14_t2  0.007291\n",
       "33      15_t2  0.179152\n",
       "34   1_winner  0.268573\n",
       "35   2_winner  0.247320\n",
       "36   3_winner  0.268070\n",
       "37   4_winner  0.293484\n",
       "38   5_winner  0.248180\n",
       "39   6_winner  0.271984\n",
       "40   7_winner  0.274882\n",
       "41   8_winner  0.263837\n",
       "42   9_winner  0.255270\n",
       "43  10_winner  0.272229\n",
       "44  11_winner  0.265944\n",
       "45  12_winner  0.253833\n",
       "46  13_winner  0.259902\n",
       "47  14_winner  0.269040\n",
       "48  15_winner -0.087652"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l1.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l1.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7289d95-1ac7-4d27-813d-6b11f28c0d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4548, 1180],\n",
       "       [1244, 3837]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f65b3571-64c7-430d-8244-b46b762439cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769 (0.010)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5da29ead-ec78-441e-816c-eb2ae6aab8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7939944134078212\n",
      "recal:  0.7852209944751382\n",
      "fscore:  0.7895833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l1,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebee315-c6f4-497d-9e04-be0d284225ac",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dad92fd-ca5e-40ed-8a06-f1bdabc32ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ridge_l2 = linear_model.LogisticRegression(penalty='l2', C = 0.01) # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4ddd862-b81a-444c-9b19-a44ffcb47051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ridge_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a11e5edf-096b-4ef2-9785-de3a0d51af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 0.775187\n"
     ]
    }
   ],
   "source": [
    "yhat_l2 = logreg_ridge_l2.predict(X_test)# the predict method will return 0 or 1\n",
    "acc = np.mean(yhat_l2 == y_test)\n",
    "print(\"Accuracy on test data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a63a024e-0ae7-4663-974d-7abe2f4507bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization parameter: 0.01\n",
      "Accuracy on the test data is 0.775187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1</td>\n",
       "      <td>-0.003611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_2</td>\n",
       "      <td>0.003331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_map</td>\n",
       "      <td>-0.008073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_start</td>\n",
       "      <td>0.029081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_t1</td>\n",
       "      <td>-0.074207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_t1</td>\n",
       "      <td>-0.046590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_t1</td>\n",
       "      <td>-0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_t1</td>\n",
       "      <td>-0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_t1</td>\n",
       "      <td>-0.006984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_t1</td>\n",
       "      <td>0.012350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_t1</td>\n",
       "      <td>-0.025941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8_t1</td>\n",
       "      <td>-0.012183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9_t1</td>\n",
       "      <td>-0.003292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10_t1</td>\n",
       "      <td>-0.004714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11_t1</td>\n",
       "      <td>-0.009163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12_t1</td>\n",
       "      <td>-0.021091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13_t1</td>\n",
       "      <td>-0.027020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14_t1</td>\n",
       "      <td>-0.066390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15_t1</td>\n",
       "      <td>0.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_t2</td>\n",
       "      <td>0.054607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_t2</td>\n",
       "      <td>0.005788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3_t2</td>\n",
       "      <td>0.041318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4_t2</td>\n",
       "      <td>0.030625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5_t2</td>\n",
       "      <td>0.003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6_t2</td>\n",
       "      <td>0.015794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7_t2</td>\n",
       "      <td>-0.003470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8_t2</td>\n",
       "      <td>-0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9_t2</td>\n",
       "      <td>0.019127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_t2</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11_t2</td>\n",
       "      <td>0.020378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12_t2</td>\n",
       "      <td>-0.019010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13_t2</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14_t2</td>\n",
       "      <td>0.023549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15_t2</td>\n",
       "      <td>0.188832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1_winner</td>\n",
       "      <td>0.229106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2_winner</td>\n",
       "      <td>0.199302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_winner</td>\n",
       "      <td>0.257157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4_winner</td>\n",
       "      <td>0.296053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5_winner</td>\n",
       "      <td>0.254535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6_winner</td>\n",
       "      <td>0.278521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7_winner</td>\n",
       "      <td>0.277709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8_winner</td>\n",
       "      <td>0.266665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9_winner</td>\n",
       "      <td>0.255282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10_winner</td>\n",
       "      <td>0.271695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11_winner</td>\n",
       "      <td>0.273370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12_winner</td>\n",
       "      <td>0.252158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13_winner</td>\n",
       "      <td>0.251835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14_winner</td>\n",
       "      <td>0.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15_winner</td>\n",
       "      <td>-0.140545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     slope\n",
       "0      team_1 -0.003611\n",
       "1      team_2  0.003331\n",
       "2        _map -0.008073\n",
       "3    t1_start  0.029081\n",
       "4        1_t1 -0.074207\n",
       "5        2_t1 -0.046590\n",
       "6        3_t1 -0.053100\n",
       "7        4_t1 -0.002321\n",
       "8        5_t1 -0.006984\n",
       "9        6_t1  0.012350\n",
       "10       7_t1 -0.025941\n",
       "11       8_t1 -0.012183\n",
       "12       9_t1 -0.003292\n",
       "13      10_t1 -0.004714\n",
       "14      11_t1 -0.009163\n",
       "15      12_t1 -0.021091\n",
       "16      13_t1 -0.027020\n",
       "17      14_t1 -0.066390\n",
       "18      15_t1  0.014134\n",
       "19       1_t2  0.054607\n",
       "20       2_t2  0.005788\n",
       "21       3_t2  0.041318\n",
       "22       4_t2  0.030625\n",
       "23       5_t2  0.003296\n",
       "24       6_t2  0.015794\n",
       "25       7_t2 -0.003470\n",
       "26       8_t2 -0.008051\n",
       "27       9_t2  0.019127\n",
       "28      10_t2  0.002793\n",
       "29      11_t2  0.020378\n",
       "30      12_t2 -0.019010\n",
       "31      13_t2  0.030645\n",
       "32      14_t2  0.023549\n",
       "33      15_t2  0.188832\n",
       "34   1_winner  0.229106\n",
       "35   2_winner  0.199302\n",
       "36   3_winner  0.257157\n",
       "37   4_winner  0.296053\n",
       "38   5_winner  0.254535\n",
       "39   6_winner  0.278521\n",
       "40   7_winner  0.277709\n",
       "41   8_winner  0.266665\n",
       "42   9_winner  0.255282\n",
       "43  10_winner  0.271695\n",
       "44  11_winner  0.273370\n",
       "45  12_winner  0.252158\n",
       "46  13_winner  0.251835\n",
       "47  14_winner  0.282600\n",
       "48  15_winner -0.140545"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The regularization parameter:\", logreg_ridge_l2.C)\n",
    "print('Accuracy on the test data is {0:f}'.format(acc))\n",
    "W_l1 = logreg_ridge_l2.coef_\n",
    "\n",
    "\n",
    "data = {'feature': xnames, 'slope': np.squeeze(W_l1)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "035b2543-26f2-4f57-bf4d-cb0d0af5e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4596, 1234],\n",
       "       [1196, 3783]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test data we can see the number of tpr, fpr, fnr, and tnr in the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(yhat_l2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4674da8-cff6-417c-a812-b1f8548b6075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749 (0.007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(logreg_ridge_l2, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24ab06ab-c282-4f0d-a763-6d4040591692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.788336192109777\n",
      "recal:  0.7935082872928176\n",
      "fscore:  0.7909137842023747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn\n",
    "# Using y_train and y_hat_logreg\n",
    "prec,recal,fscore,_= precision_recall_fscore_support(y_test,yhat_l2,average='binary')\n",
    "print('prec: ', prec)\n",
    "print('recal: ', recal)\n",
    "print('fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd8a5f-5d37-4bb5-99ba-29caa7c434d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5b07f-17bc-4736-b0cd-2c7afab7d2c6",
   "metadata": {},
   "source": [
    "## Polynomial Transformation Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d5fa31-5713-4d9b-ad98-c503025097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful polynomial library\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3981e86-6482-478b-bc26-83d6f3a7c5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.34 GiB for an array with shape (32425, 22099) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-f24c9aac2a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Train features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpoly_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mx_poly_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Logistic regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\justin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\justin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1785\u001b[0m                 \u001b[0mXP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m                 XP = np.empty((n_samples, self.n_output_features_),\n\u001b[0m\u001b[0;32m   1788\u001b[0m                               dtype=X.dtype, order=self.order)\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.34 GiB for an array with shape (32425, 22099) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "rmses = []\n",
    "degrees = np.arange(3, 4)\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    poly_reg = linear_model.LogisticRegression(penalty='l2', C = 0.01)\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(X_test)\n",
    "    poly_predict = poly_reg.predict(x_poly_test)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "    \n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575918e-822a-46d4-9e32-32f4ea891072",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_mean = np.mean(MSEvl,axis=1)\n",
    "MSE_std  = np.std(MSEvl,axis=1) / np.sqrt(nfold-1)\n",
    "plt.errorbar(dval, MSE_mean, yerr=MSE_std, fmt='-')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Model order')\n",
    "plt.ylabel('Validation MSE')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248b5b4-2458-43cf-999d-1b1c521a0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "imin = np.argmin(MSE_mean)\n",
    "print(\"The selected model order is {0:d}\".format(dval[imin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb0ded-2cff-4252-a196-839ab7a9f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# create transform\n",
    "trans = PolynomialFeatures(degree=dval[imin])\n",
    "# fit and transform\n",
    "X = trans.fit_transform(X)\n",
    "print('Degree: %d, Features: %d' % (dval[imin], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0432f-db23-4621-9bac-0e74fccc938a",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
